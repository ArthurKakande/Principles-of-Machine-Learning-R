{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Cross Validation and Model Selection\n",
    "\n",
    "In a previous lab you created a model with l2 or ridge regularization and l1 or lasso regularization. In both cases, an apparently optimum value of the regularization parameter was found. This process is an example of **model selection**. The goal of model selection is to find the best performing model for the problem at hand. Model selection is a very general term and can apply to at least the following common cases:\n",
    "- Selection of optimal model **hyperparameters**. Hyperparameters are parameters which determine the characteristics of a model. Hyperparameters are distinct from the model parameters. For example, for the case of l2 regularized regression, the degree of regularization is determined by a hyperparameter, which is distinct from the regression coefficients or parameters. \n",
    "- **Feature selection** is the process of determining which features should be used in a model. \n",
    "- Comparing different model types is an obvious case of model selection. \n",
    "\n",
    "If you are thinking that the model selection process is closely related to model training, you are correct. Model selection is a component of model training. However, one must be careful, as applying a poor model selection method can lead to an over-fit model!\n",
    "\n",
    "## Overview of k-fold cross validation\n",
    "\n",
    "The questions remain, how good are the hyperparameter estimates perviously obtained for the l2 and l1 regularization parameters and are there better ways to estimate these parameters? The answer to both questions is to use **resampling methods**. Resampling methods repeat a calculation multiple times using randomly selected subsets of the complete dataset.  In fact, resampling methods are generally the best approach to model selection problems. \n",
    "\n",
    "\n",
    "**K-folod Cross validation** is a widely used resampling method. In cross validaton a dataset is divided into **k folds**. Each fold contains $\\frac{1}{k}$ cases and is created by **Bernoulli random sampling** of the full data set. A computation is performed on $k-1$ folds of the full dataset. The $k^{th}$ fold is **held back** and is used for testing the result. The compuation is performed $k$ times and model parameters are averaged (mean taken) over the results of the $k$ folds. For each iteration, $k-1$ folds are used for training and the $k^{th}$ fold is used for testing. \n",
    "\n",
    "4-fold cross validation is illustrated in the figure below. To ensure the data are randomly sampled the data is randomly shuffled at the start of the procedure. The random samples can then be efficiently sub-sampled as shown in the figure. The model is trained and tested four times. For each iteration the data is trained with three folds of the data and tested with the fold shown in the dark shading. \n",
    "\n",
    "<img src=\"img/CrossValidation.jpg\" alt=\"Drawing\" style=\"width:750px; height:400px\"/>\n",
    "<center> **Resampling scheme for 4-fold cross validation**</center>\n",
    "\n",
    "## Introduction to nested cross validation\n",
    "\n",
    "Unfortunately, simple cross validation alone does not provide an unbiased approach to model selection. The problem with evaluating model performance with simple cross validation uses the same data samples as the model selection process. This situation will lead to model over fitting wherein the model selection is learned based on the evaluation data. The result is usually unrealistically optimistic model performance estimates.\n",
    "\n",
    "To obtain unbiased estimates of expected model performance while performing model selection, it is necessary to use **nested cross validation**. As the name implies, nested cross validation is performed though a pair of nested CV loops. The outer loop uses a set of folds to perform model evaluation. The inner loop performs model selection using another randomly sampled set of  folds not used for evalution by the outer loop. This algorithm allows model selection and evaluation to proceed with randomly sampled subsets of the full data set, thereby avoiding model selection bias. \n",
    "\n",
    "## Cross validation and compuational efficiency\n",
    "\n",
    "As you may have surmised, cross validation can be compuationally intensive. Processing each fold of a cross validation requires fitting and evaluating the model. It is desireable to compute a reasonable number of folds. Since the results are averaged over the folds, a small number of folds can lead to significant variablity in the final result. However, with large data sets or complex models, the number of folds must be limited in order to complete the cross validation process in a reasonable amount of time. It is, therefore, necessary to trade off accuracy of the cross validation result with the practical consideration of the required compuatational resources. \n",
    "\n",
    "As mentioned earlier, other resampling methods exist. For example, leave-one-out resampling has the same number of folds as data cases. Such methods provide optimal unbiased estimates of model performance. Unfortunately, as you might think, such methods are compuationally intensive and are only suitable for small datasets. In practice k-fold cross validation is a reasonable way to explore bias-variance trade-off with reasonable compuational resources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Features and Labels\n",
    "\n",
    "With the above theory in mind, you will now try an example. \n",
    "\n",
    "As a first step, execute the code in the cell below to load the packages required for this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "Loading required package: lattice\n",
      "Loading required package: Matrix\n",
      "Loading required package: foreach\n",
      "Loaded glmnet 2.0-10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Import packages\n",
    "library(ggplot2)\n",
    "library(repr)\n",
    "library(dplyr)\n",
    "library(caret)\n",
    "library(glmnet)\n",
    "\n",
    "options(repr.plot.width=5, repr.plot.height=5) # Set the initial plot area dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the preprocessed files containing the features and the labels. The preprocessing includes the following:\n",
    "1. Cleaning missing values.\n",
    "2. Aggregate categories of certain categorical variables. \n",
    "3. Encoding categorical variables as binary dummy variables.\n",
    "4. Standardization of numeric variables. \n",
    "\n",
    "Execute the code in the cell below to load the features and labels as numpy arrays for the example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 999  23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'X'</li>\n",
       "\t<li>'Customer_ID'</li>\n",
       "\t<li>'checking_account_status'</li>\n",
       "\t<li>'loan_duration_mo'</li>\n",
       "\t<li>'credit_history'</li>\n",
       "\t<li>'purpose'</li>\n",
       "\t<li>'loan_amount'</li>\n",
       "\t<li>'savings_account_balance'</li>\n",
       "\t<li>'time_employed_yrs'</li>\n",
       "\t<li>'payment_pcnt_income'</li>\n",
       "\t<li>'gender_status'</li>\n",
       "\t<li>'other_signators'</li>\n",
       "\t<li>'time_in_residence'</li>\n",
       "\t<li>'property'</li>\n",
       "\t<li>'age_yrs'</li>\n",
       "\t<li>'other_credit_outstanding'</li>\n",
       "\t<li>'home_ownership'</li>\n",
       "\t<li>'number_loans'</li>\n",
       "\t<li>'job_category'</li>\n",
       "\t<li>'dependents'</li>\n",
       "\t<li>'telephone'</li>\n",
       "\t<li>'foreign_worker'</li>\n",
       "\t<li>'bad_credit'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'X'\n",
       "\\item 'Customer\\_ID'\n",
       "\\item 'checking\\_account\\_status'\n",
       "\\item 'loan\\_duration\\_mo'\n",
       "\\item 'credit\\_history'\n",
       "\\item 'purpose'\n",
       "\\item 'loan\\_amount'\n",
       "\\item 'savings\\_account\\_balance'\n",
       "\\item 'time\\_employed\\_yrs'\n",
       "\\item 'payment\\_pcnt\\_income'\n",
       "\\item 'gender\\_status'\n",
       "\\item 'other\\_signators'\n",
       "\\item 'time\\_in\\_residence'\n",
       "\\item 'property'\n",
       "\\item 'age\\_yrs'\n",
       "\\item 'other\\_credit\\_outstanding'\n",
       "\\item 'home\\_ownership'\n",
       "\\item 'number\\_loans'\n",
       "\\item 'job\\_category'\n",
       "\\item 'dependents'\n",
       "\\item 'telephone'\n",
       "\\item 'foreign\\_worker'\n",
       "\\item 'bad\\_credit'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'X'\n",
       "2. 'Customer_ID'\n",
       "3. 'checking_account_status'\n",
       "4. 'loan_duration_mo'\n",
       "5. 'credit_history'\n",
       "6. 'purpose'\n",
       "7. 'loan_amount'\n",
       "8. 'savings_account_balance'\n",
       "9. 'time_employed_yrs'\n",
       "10. 'payment_pcnt_income'\n",
       "11. 'gender_status'\n",
       "12. 'other_signators'\n",
       "13. 'time_in_residence'\n",
       "14. 'property'\n",
       "15. 'age_yrs'\n",
       "16. 'other_credit_outstanding'\n",
       "17. 'home_ownership'\n",
       "18. 'number_loans'\n",
       "19. 'job_category'\n",
       "20. 'dependents'\n",
       "21. 'telephone'\n",
       "22. 'foreign_worker'\n",
       "23. 'bad_credit'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"X\"                        \"Customer_ID\"             \n",
       " [3] \"checking_account_status\"  \"loan_duration_mo\"        \n",
       " [5] \"credit_history\"           \"purpose\"                 \n",
       " [7] \"loan_amount\"              \"savings_account_balance\" \n",
       " [9] \"time_employed_yrs\"        \"payment_pcnt_income\"     \n",
       "[11] \"gender_status\"            \"other_signators\"         \n",
       "[13] \"time_in_residence\"        \"property\"                \n",
       "[15] \"age_yrs\"                  \"other_credit_outstanding\"\n",
       "[17] \"home_ownership\"           \"number_loans\"            \n",
       "[19] \"job_category\"             \"dependents\"              \n",
       "[21] \"telephone\"                \"foreign_worker\"          \n",
       "[23] \"bad_credit\"              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auto_prices = read.csv('German_Credit_Preped.csv')\n",
    "print(dim(auto_prices))\n",
    "names(auto_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset\n",
    "\n",
    "You must now create randomly sampled training and test data sets. The `createDataPartition` function from the R caret package is used  to create indices for the training data sample. Execute this code and note the dimensions of the resulting data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>700</li>\n",
       "\t<li>23</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 700\n",
       "\\item 23\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 700\n",
       "2. 23\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 700  23"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>299</li>\n",
       "\t<li>23</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 299\n",
       "\\item 23\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 299\n",
       "2. 23\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 299  23"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1955)\n",
    "## Randomly sample cases to create independent training and test data\n",
    "partition = createDataPartition(auto_prices[,'bad_credit'], times = 1, p = 0.7, list = FALSE)\n",
    "training = auto_prices[partition,] # Create the training sample\n",
    "dim(training)\n",
    "test = auto_prices[-partition,] # Create the test sample\n",
    "dim(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale numeric features\n",
    "\n",
    "Numeric features must be rescaled so they have a similar range of values. Rescaling prevents features from having an undue influence on model training simply because then have a larger range of numeric variables. \n",
    "\n",
    "The code in the cell below uses the `preProcess` function from the caret function. The processing is as follows:\n",
    "1. The preprocessing model object is computed. In this case the processing includes centering and scaling the numeric feature. Notice that this model is fit only ot the training data.\n",
    "2. The scalling is appled both the test and training partitions.\n",
    "\n",
    "Execute the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>loan_duration_mo</th><th scope=col>loan_amount</th><th scope=col>payment_pcnt_income</th><th scope=col>time_in_residence</th><th scope=col>age_yrs</th><th scope=col>number_loans</th><th scope=col>dependents</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 2.2422240 </td><td> 0.9130877 </td><td>-0.8632953 </td><td>-0.7888462 </td><td>-1.20616846</td><td>-0.7009378 </td><td>-0.429150  </td></tr>\n",
       "\t<tr><td>-0.7420395 </td><td>-0.4105541 </td><td>-0.8632953 </td><td> 0.1208611 </td><td> 1.25859356</td><td>-0.7009378 </td><td> 2.326859  </td></tr>\n",
       "\t<tr><td> 1.7448468 </td><td> 1.5761103 </td><td>-0.8632953 </td><td> 1.0305684 </td><td> 0.89344363</td><td>-0.7009378 </td><td> 2.326859  </td></tr>\n",
       "\t<tr><td> 0.2527150 </td><td> 0.5419186 </td><td> 0.0319739 </td><td> 1.0305684 </td><td> 1.62374349</td><td> 1.0768031 </td><td> 2.326859  </td></tr>\n",
       "\t<tr><td> 1.2474695 </td><td> 1.9788682 </td><td>-0.8632953 </td><td> 1.0305684 </td><td>-0.01943119</td><td>-0.7009378 </td><td> 2.326859  </td></tr>\n",
       "\t<tr><td> 0.2527150 </td><td>-0.1568132 </td><td> 0.0319739 </td><td> 1.0305684 </td><td> 1.62374349</td><td>-0.7009378 </td><td>-0.429150  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllll}\n",
       " loan\\_duration\\_mo & loan\\_amount & payment\\_pcnt\\_income & time\\_in\\_residence & age\\_yrs & number\\_loans & dependents\\\\\n",
       "\\hline\n",
       "\t  2.2422240  &  0.9130877  & -0.8632953  & -0.7888462  & -1.20616846 & -0.7009378  & -0.429150  \\\\\n",
       "\t -0.7420395  & -0.4105541  & -0.8632953  &  0.1208611  &  1.25859356 & -0.7009378  &  2.326859  \\\\\n",
       "\t  1.7448468  &  1.5761103  & -0.8632953  &  1.0305684  &  0.89344363 & -0.7009378  &  2.326859  \\\\\n",
       "\t  0.2527150  &  0.5419186  &  0.0319739  &  1.0305684  &  1.62374349 &  1.0768031  &  2.326859  \\\\\n",
       "\t  1.2474695  &  1.9788682  & -0.8632953  &  1.0305684  & -0.01943119 & -0.7009378  &  2.326859  \\\\\n",
       "\t  0.2527150  & -0.1568132  &  0.0319739  &  1.0305684  &  1.62374349 & -0.7009378  & -0.429150  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "loan_duration_mo | loan_amount | payment_pcnt_income | time_in_residence | age_yrs | number_loans | dependents | \n",
       "|---|---|---|---|---|---|\n",
       "|  2.2422240  |  0.9130877  | -0.8632953  | -0.7888462  | -1.20616846 | -0.7009378  | -0.429150   | \n",
       "| -0.7420395  | -0.4105541  | -0.8632953  |  0.1208611  |  1.25859356 | -0.7009378  |  2.326859   | \n",
       "|  1.7448468  |  1.5761103  | -0.8632953  |  1.0305684  |  0.89344363 | -0.7009378  |  2.326859   | \n",
       "|  0.2527150  |  0.5419186  |  0.0319739  |  1.0305684  |  1.62374349 |  1.0768031  |  2.326859   | \n",
       "|  1.2474695  |  1.9788682  | -0.8632953  |  1.0305684  | -0.01943119 | -0.7009378  |  2.326859   | \n",
       "|  0.2527150  | -0.1568132  |  0.0319739  |  1.0305684  |  1.62374349 | -0.7009378  | -0.429150   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  loan_duration_mo loan_amount payment_pcnt_income time_in_residence\n",
       "1  2.2422240        0.9130877  -0.8632953          -0.7888462       \n",
       "2 -0.7420395       -0.4105541  -0.8632953           0.1208611       \n",
       "3  1.7448468        1.5761103  -0.8632953           1.0305684       \n",
       "4  0.2527150        0.5419186   0.0319739           1.0305684       \n",
       "5  1.2474695        1.9788682  -0.8632953           1.0305684       \n",
       "6  0.2527150       -0.1568132   0.0319739           1.0305684       \n",
       "  age_yrs     number_loans dependents\n",
       "1 -1.20616846 -0.7009378   -0.429150 \n",
       "2  1.25859356 -0.7009378    2.326859 \n",
       "3  0.89344363 -0.7009378    2.326859 \n",
       "4  1.62374349  1.0768031    2.326859 \n",
       "5 -0.01943119 -0.7009378    2.326859 \n",
       "6  1.62374349 -0.7009378   -0.429150 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_cols = c('loan_duration_mo', 'loan_amount', 'payment_pcnt_income',\n",
    "             'time_in_residence', 'age_yrs', 'number_loans', 'dependents')\n",
    "preProcValues <- preProcess(training[,num_cols], method = c(\"center\", \"scale\"))\n",
    "\n",
    "training[,num_cols] = predict(preProcValues, training[,num_cols])\n",
    "test[,num_cols] = predict(preProcValues, test[,num_cols])\n",
    "head(training[,num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the logistic regression model\n",
    "\n",
    "To create a baseline for comparison you will now create a logistic regression model without cross validation. This model uses a fixed set of hyperparameters. You will compare the performance of this model with the cross validation results computed subsequently. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, execute the code in the cell below to creat training and testing splits of the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is time to compute the logistic regression model. The code in the cell below does the following:\n",
    "1. Define a logistic regression model object using the `LogisticRegression` method from the Scikit-Learn `linear_model` package.\n",
    "2. Fit the linear model using the numpy arrays of the features and the labels for the training data set.\n",
    "\n",
    "Execute this code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>bad_credit</th><th scope=col>score</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>13</th><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>14</th><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>17</th><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>19</th><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>21</th><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>22</th><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>23</th><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>29</th><td>1</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>30</th><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>39</th><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>41</th><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>43</th><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>48</th><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>51</th><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>59</th><td>1</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>67</th><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>68</th><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>70</th><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>71</th><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>78</th><td>0</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & bad\\_credit & score\\\\\n",
       "\\hline\n",
       "\t13 & 1 & 0\\\\\n",
       "\t14 & 0 & 1\\\\\n",
       "\t17 & 0 & 1\\\\\n",
       "\t19 & 0 & 0\\\\\n",
       "\t21 & 0 & 0\\\\\n",
       "\t22 & 0 & 0\\\\\n",
       "\t23 & 0 & 0\\\\\n",
       "\t29 & 1 & 1\\\\\n",
       "\t30 & 0 & 0\\\\\n",
       "\t39 & 0 & 0\\\\\n",
       "\t41 & 0 & 0\\\\\n",
       "\t43 & 0 & 0\\\\\n",
       "\t48 & 0 & 0\\\\\n",
       "\t51 & 0 & 0\\\\\n",
       "\t59 & 1 & 1\\\\\n",
       "\t67 & 0 & 1\\\\\n",
       "\t68 & 1 & 0\\\\\n",
       "\t70 & 0 & 0\\\\\n",
       "\t71 & 0 & 0\\\\\n",
       "\t78 & 0 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | bad_credit | score | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 13 | 1 | 0 | \n",
       "| 14 | 0 | 1 | \n",
       "| 17 | 0 | 1 | \n",
       "| 19 | 0 | 0 | \n",
       "| 21 | 0 | 0 | \n",
       "| 22 | 0 | 0 | \n",
       "| 23 | 0 | 0 | \n",
       "| 29 | 1 | 1 | \n",
       "| 30 | 0 | 0 | \n",
       "| 39 | 0 | 0 | \n",
       "| 41 | 0 | 0 | \n",
       "| 43 | 0 | 0 | \n",
       "| 48 | 0 | 0 | \n",
       "| 51 | 0 | 0 | \n",
       "| 59 | 1 | 1 | \n",
       "| 67 | 0 | 1 | \n",
       "| 68 | 1 | 0 | \n",
       "| 70 | 0 | 0 | \n",
       "| 71 | 0 | 0 | \n",
       "| 78 | 0 | 0 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   bad_credit score\n",
       "13 1          0    \n",
       "14 0          1    \n",
       "17 0          1    \n",
       "19 0          0    \n",
       "21 0          0    \n",
       "22 0          0    \n",
       "23 0          0    \n",
       "29 1          1    \n",
       "30 0          0    \n",
       "39 0          0    \n",
       "41 0          0    \n",
       "43 0          0    \n",
       "48 0          0    \n",
       "51 0          0    \n",
       "59 1          1    \n",
       "67 0          1    \n",
       "68 1          0    \n",
       "70 0          0    \n",
       "71 0          0    \n",
       "78 0          0    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_model = function(df, threshold){\n",
    "    df$score = ifelse(df$score > threshold, 1, 0)\n",
    "    df\n",
    "}\n",
    "\n",
    "set.seed(5566)\n",
    "logistic_mod = glm(bad_credit ~ loan_duration_mo + loan_amount +  \n",
    "                                 payment_pcnt_income + age_yrs + \n",
    "                                 checking_account_status + credit_history + \n",
    "                                 purpose + gender_status + time_in_residence +\n",
    "                                 property, \n",
    "                    family = binomial, data = training)\n",
    "\n",
    "test$score = predict(logistic_mod, newdata = test, type = 'response')\n",
    "test = score_model(test, 0.5)\n",
    "test[1:20, c('bad_credit','score')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below computes and displays metrics and the ROC curve for the model using the test data subset. Execute this code and examine the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Negative Positive\n",
      "TrueNeg      187       32\n",
      "TruePos       47       33\n",
      "\n",
      "accuracy  = 0.736 \n",
      "precision = 0.508 \n",
      "recall    = 0.412 \n",
      "F1        =  0.455 \n"
     ]
    }
   ],
   "source": [
    "logistic.eval <- function(df){ \n",
    "  # First step is to find the TP, FP, TN, FN cases\n",
    "  df$conf = ifelse(df$bad_credit == 1 & df$score == 1, 'TP',\n",
    "                    ifelse(df$bad_credit == 0 & df$score == 1, 'FP',\n",
    "                           ifelse(df$bad_credit == 0 & df$score == 0, 'TN', 'FN')))\n",
    "\n",
    "  # Elements of the confusion matrix\n",
    "  TP = length(df[df$conf == 'TP', 'conf'])\n",
    "  FP = length(df[df$conf == 'FP', 'conf'])\n",
    "  TN = length(df[df$conf == 'TN', 'conf'])\n",
    "  FN = length(df[df$conf == 'FN', 'conf'])\n",
    "  \n",
    "  ## Confusion matrix as data frame\n",
    "  out = data.frame(Negative = c(TN, FN), Positive = c(FP, TP))\n",
    "  row.names(out) = c('TrueNeg', 'TruePos')\n",
    "  print(out)  \n",
    "  \n",
    "  # Compute and print metrics\n",
    "  P = TP/(TP + FP)\n",
    "  R = TP/(TP + FN)  \n",
    "  F1 = 2*P*R/(P+R)  \n",
    "  cat('\\n')\n",
    "  cat(paste('accuracy  =', as.character(round((TP + TN)/(TP + TN + FP + FN), 3)), '\\n'))      \n",
    "  cat(paste('precision =', as.character(round(P, 3)), '\\n'))     \n",
    "  cat(paste('recall    =', as.character(round(R, 3)), '\\n'))\n",
    "  cat(paste('F1        = ', as.character(round(F1,3)),'\\n'))\n",
    "}\n",
    "logistic.eval(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results look promisting, with most of the metrics having resonable values. The question is now, how will these performance estimates hold up to cross validaton?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validate model\n",
    "\n",
    "To compute a better estimate of model performance, you can perform simple cross validation. The code in the cell performs the following processing:\n",
    "1. Create a list of the metrics to be computed for each fold. \n",
    "2. Defines a logistic regression model object.\n",
    "3. A 10 fold cross validaton is performed using the `cross_validate` function from the Scikit Learn `model_selection` package.\n",
    "\n",
    "Execute this code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = Labels.reshape(Labels.shape[0],)\n",
    "scoring = ['precision_macro', 'recall_macro', 'roc_auc']\n",
    "logistic_mod = linear_model.LogisticRegression(C = 1.0, class_weight = {0:0.1, 0:0.9}) \n",
    "scores = ms.cross_validate(logistic_mod, Features, Labels, scoring=scoring,\n",
    "                        cv=10, return_train_score=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below displays the performance metrics along with the mean and standard deviation, computed for each fold to the cross validation. The 'macro' versions of precision and recall are used. These macro versions average over the positive and negative cases. \n",
    "\n",
    "Execute this code and examine the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Precision    Recall,    AUC\n",
      "Fold 1   0.741        0.710      0.826\n",
      "Fold 2   0.672        0.626      0.761\n",
      "Fold 3   0.650        0.640      0.772\n",
      "Fold 4   0.672        0.636      0.751\n",
      "Fold 5   0.757        0.717      0.799\n",
      "Fold 6   0.757        0.717      0.798\n",
      "Fold 7   0.593        0.583      0.696\n",
      "Fold 8   0.753        0.726      0.836\n",
      "Fold 9   0.700        0.669      0.796\n",
      "Fold 10   0.651        0.649      0.746\n",
      "----------------------------------------\n",
      "Mean     0.695        0.667      0.778\n",
      "Std      0.053        0.046      0.040\n"
     ]
    }
   ],
   "source": [
    "def print_format(f,x,y,z):\n",
    "    print('Fold %1d   %4.3f        %4.3f      %4.3f' % (f, x, y, z))\n",
    "\n",
    "def print_cv(scores):\n",
    "    fold = [x + 1 for x in range(len(scores['test_precision_macro']))]\n",
    "    print('         Precision    Recall,    AUC')\n",
    "    [print_format(f,x,y,z) for f,x,y,z in zip(fold, scores['test_precision_macro'], \n",
    "                                          scores['test_recall_macro'],\n",
    "                                          scores['test_roc_auc'])]\n",
    "    print('-' * 40)\n",
    "    print('Mean     %4.3f        %4.3f      %4.3f' % \n",
    "          (np.mean(scores['test_precision_macro']), np.mean(scores['test_recall_macro']), np.mean(scores['test_roc_auc'])))  \n",
    "    print('Std      %4.3f        %4.3f      %4.3f' % \n",
    "          (np.std(scores['test_precision_macro']), np.std(scores['test_recall_macro']), np.std(scores['test_roc_auc'])))\n",
    "\n",
    "print_cv(scores)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there is considerable variability in each of the performance metrics from fold to fold. Even so, the standard deviations are at least an order of magnitude than the means. It is clear that **any one fold does not provide a representative value of the performance metrics**. The later is a key point as to why cross validation is important when evaluating a machine learning model.  \n",
    "\n",
    "Compare the performance metric values to the values obtained for the baseline model you created above. In general the metrics obtained by cross validation are lower. However, the metrics obtained for the baseline model are within 1 standard deviation of the average metrics from cross validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize hyperparameters with nested cross validation\n",
    "\n",
    "Given the variability observed in cross validation, it should be clear that performing model selection from a single training and evauation is an uncertain proposition at best. Fortunately, the nested cross validation approach provides a better way to perform model selection. However, there is no guarantee that a model selection process will, in fact, improve a model. In some cases, it may prove to be that model selection has minimal impact. \n",
    "\n",
    "To start the nested cross validation process it is necessary to define the randomly sampled folds for the inner and outer loops. The code in the cell below uses the `KFolds` function from the Scikit Learn `model_selection` package to define fold selection objects. Notice that the `shuffle = True` argument is used in both cases. This argument specifies that a random suffle is preformed before folds are created, ensuring that the sampling of the folds for the inside and outside loops are independent. Notice that by creating these independent fold objects there is no need to actually create nested loops for this process. \n",
    "\n",
    "Execute this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed(123)\n",
    "inside = ms.KFold(n_splits=10, shuffle = True)\n",
    "nr.seed(321)\n",
    "outside = ms.KFold(n_splits=10, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important decision in model selection searches is the choice of performance metric used to find the best model. For classification probems Scikit Learn uses accuracy as the default metric. However, as you have seen previously, accuracy is not necessarily the best metric, particularly when there is a class imbalance as is the case here. There are a number of alternatives which one could choose for such a situation. In this case AUC will be used. \n",
    "\n",
    "The code below uses the `inside` k-fold object to execute the inside loop of the nested cross validation. Specifically, the steps are:\n",
    "1. Define a dictionary with the grid of parameter values to search over. In this case there is only one parameter, `C`, with a list of values to try. In a more general case, the dictionary can contain values from multiple parameters, creating a multi-dimensional grid that the cross validation process will iterate over. In this case there are 5 hyperparameter values in the grid and 10-fold cross validation is being used. Thus, the model will be trained and evaluated 50 times. \n",
    "2. The logistic regression model object is defined. \n",
    "3. The cross validation search over the parameter grid is performed using the `GridSearch` function from the Scikit Learn `model_selection` package. Notice that the cross validation folds are computed using the `inside` k-fold object.\n",
    "\n",
    "\n",
    "****\n",
    "**Note:** Somewhat confusingly, the Scikit Learn `LogisticRegression` function uses a regularization parameter `C` which is the inverse of the usual l2 regularization parameter $\\lambda$. Thus, the smaller the parameter the stronger the regulation \n",
    "****\n",
    "\n",
    "Execute this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nr.seed(3456)\n",
    "## Define the dictionary for the grid search and the model object to search on\n",
    "param_grid = {\"C\": [0.1, 1, 10, 100, 1000]}\n",
    "## Define the logistic regression model\n",
    "logistic_mod = linear_model.LogisticRegression(class_weight = {0:0.1, 0:0.9}) \n",
    "\n",
    "## Perform the grid search over the parameters\n",
    "clf = ms.GridSearchCV(estimator = logistic_mod, param_grid = param_grid, \n",
    "                      cv = inside, # Use the inside folds\n",
    "                      scoring = sklm.make_scorer(sklm.roc_auc_score),\n",
    "                      return_train_score = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validated grid search obect, `clf`, has been creted. \n",
    "\n",
    "The code in the cell below fits the cross validated model using the `fit`method. The AUC for each hyperparameter and fold is displayed as an array. Finally, the hyperparameter for the model with the best average AUC is displayed.  Execute this code and  examine the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57738095 0.5922619  0.58134921 0.58134921 0.58134921]\n",
      "[0.72193347 0.73440748 0.74116424 0.74116424 0.74116424]\n",
      "[0.65873016 0.70138889 0.69047619 0.69047619 0.69047619]\n",
      "[0.66519546 0.69083649 0.69083649 0.68263976 0.68263976]\n",
      "[0.61218361 0.61540112 0.61540112 0.61540112 0.61540112]\n",
      "[0.64282375 0.64446003 0.64446003 0.66058906 0.66058906]\n",
      "[0.70680147 0.69117647 0.69944853 0.69944853 0.69944853]\n",
      "[0.62474012 0.67567568 0.66216216 0.66216216 0.66216216]\n",
      "[0.71985447 0.7006237  0.70738046 0.70738046 0.70738046]\n",
      "[0.62268519 0.65277778 0.65277778 0.65277778 0.65277778]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fit thhe cross validated grid search over the data \n",
    "clf.fit(Features, Labels)\n",
    "keys = list(clf.cv_results_.keys())\n",
    "for key in keys[6:16]:\n",
    "    print(clf.cv_results_[key])\n",
    "## And print the best parameter value\n",
    "clf.best_estimator_.C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The array of AUC metrics has dimensions 10 folds X  hyperparameter values. As you might expect by now, there is considerable variation in the AUC from fold to fold for each hyperparamter value, or column. \n",
    "\n",
    "Evidently, the optimal hyperparameter value is 1.0. \n",
    "\n",
    "To help understand this behavior a bit more, the code in the cell below does the following:\n",
    "1. Compute and display the mean and standard deviation of the AUC for each hyperparameter value.\n",
    "2. Plot the AUC values for each fold vs. the hyperparameter values. The mean AUC for each hyperparameter value is shown with a red +. \n",
    "\n",
    "Execute this code and examine the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics by parameter\n",
      "Parameter   Mean perforance   STD performance\n",
      "    0.10      0.65523              0.04632\n",
      "    1.00      0.66990              0.04118\n",
      "   10.00      0.66855              0.04473\n",
      "  100.00      0.66934              0.04381\n",
      " 1000.00      0.66934              0.04381\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAElCAYAAADOTWQ3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzsnXmcXEW1+L+nu2ff9yXJZIHsLAmEJLLvi0ISBdnUB8gTN+Cp76HA8ykPQVD5iYg8NxRUQNQQk7AlIosQICEJAUJ2yD5bZt9nerr7/P6o2zO3J7MlmUn3JPX9fPrTfevWrT63bvc991Sdc0pUFYvFYrFYDhZPtAWwWCwWy8jGKhKLxWKxHBJWkVgsFovlkLCKxGKxWCyHhFUkFovFYjkkrCKxWCwWyyFhFckIR0TuEZFqEamItixHKiLyORH5R7TlABCRu0TkiWjLYekbEVEROTbachxOrCI5zIjIThFpE5FmEakUkcdEJPUg2xoD/CcwTVULh1bSIx8RGef86X391VPVJ1X1wsMll+XAEJHHReSeaMtxNGMVSXS4TFVTgZOAU4DvHmgDzs1vLFCjqvsO8njLANh+OnBGWp+NNHljEatIooiqlgIvAscBiEiGiPxORMpFpNQZtvI6+64XkTdF5EERqQVeA14Cih3r5nGn3jwR2SAi9SLymohMDX+fYw19R0Q+AFpExOeU3SYiH4hIi/P9BSLyoog0icg/RSTL1cbfRKRCRBpE5HURme7a97iIPCIizzvHrhKRY1z7p4vISyJS61hjdzrlHhG5XUQ+FpEaEfmriGT31mcicraI7BWRb4vIPqevFojIJ0Vkq9P2na76/bX9uvNe7/ThJ3rp57ucshUDnUcPOec6/eR1lX3a6XtEZLaIrBGRRqeNn/bzU+mTAa73SSKyzrkWfxORv/T15O4674eda7tZRM5z7b9BRDY5bW0XkS+79oWvyXfEDLE+JiJZIvKciFSJSJ3zebTrmNec3/dbTt8/KyI5IvKk0yerRWScq/4UV59vEZErnfKbgM8B3w6345QXi8gzzvfvEJFbXW3dJSILReQJEWkEru/RF4O5dm87fV4uIr8Qkfg++vU1Efn3Hv3s/i31el4jDlW1r8P4AnYC5zufxwAbgB8424uBXwMpQD7wDvBlZ9/1QAC4BfABScDZwF5X25OAFuACIA74NvAREO/67vec701yla0ECoBRwD7gXWAmkAC8Anzf9R1fBNKcfT8D3nPtexyoBWY7Mj4JPO3sSwPKMUNxic72HGffNxwZRjvt/hr4cx/9d7bTD99zzvFLQBXwlNPmdKAdmDBQ28A4QAGfq/3e+vl6YMVA59GLrB8DF7i2/wbc7nx+G/iC8zkVmDvI389dwBMDXW/ntQv4D2ffZwA/cE8f7YbP+5tO/auABiDb2f8p4BhAgLOAVuCkHtfkR04fJwE5wOVAstNHfwMWu77vNUfWY4AMYCOwFTjf6fc/Ao85dVOAPcANzr6TgGpguut3d4+rbQ+w1vmNxAMTgO3ARa4+7AQWOHWTDvDanQzMdWQZB2wCvuGqq8CxrvP89x79vGIw5zWSXlEX4Gh7YW7czUC980f/P+ePVwB0uH/UwDXAq87n64HdPdo6m0hF8j/AX13bHqAUONv13V/sRZ7PubafAX7p2r7FfQPocWym86fJcLYfBx517f8ksNl1Luv6aGcTcJ5ru8j5o/t6qXs20AZ4ne00R4Y5rjprgQUDtU3fiqRnP7v//H2eRy+y3gP83iVnCzDW2X4d+F8g9wB/P3fRrUj6vN7Amc5nce1fQf+KpKxH/XdwlF0v9RcD/+G6Jn4gsR+5ZwB1ru3XgP92bf8/4EXX9mU4DykYpfZGj/Z+jfOAw/6KZE4v1/AOuhXTXcDrB3vteqn7DeDvru3BKpJ+z2skvezYYHRYoKr/dBeIyPGYJ8FyEQkXezBPLGHcn3ujGKOcAFDVkIjswVga/bVR6frc1st2qiOjF7gX+CyQB4ScOrmYp1cAt/dYa/hYjBX0cR9yjwX+LiIhV1kQo1xLe6lfo6pBl3y9nUP4e/truy/66+f+zqMnTwFvichXMRbBu6oavj43AncDm0VkB/C/qvrcINsN09/1DgKl6tydHAb6/fSsv8v5DkTkEuD7GCvIg7E01rvqVqlqe3hDRJKBB4GLgfDQaJqIeF3XblC/O8w1nCMi9a79PuBPfZzHWMyQr7u+F3jDtT1QX/R57URkEvBTYBamH3yYh5cD5UDPK2axcySxwx6MRZKrqpnOK11Vp7vqDJSquQzz4wRAjEYaQ+TN+FDSPV8LzMcMP2RgnujBDHcMxB7MMEZf+y5xnXemqiaqmUM6VPpru6++6K+P+juPyEZUN2Juxpdg+u4p175tqnoNZgjzR8BCEUkZTLsu+rve5cAocT2VOPv6o2f9EqBMRBIwluoDQIGqZgIvEHnde/bZfwKTMZZiOsZCgsH9VnqyB/hXj2uYqqpf7eO79wA7etRPU9VP9iNvBP1dO+CXwGZgonNud/ZzXi0YZRPG7V050HmNGKwiiRFUtRz4B/D/RCRdzCTxMSJy1gE081fgUyJynojEYf7MHcBbQyRmmtNeDebP8cMDOPY5oFBEviEiCSKSJiJznH2/Au4VkbEAIpInIvOHSOb+2q7CWFUTDqC9/s6jN54CbsXcSP8WLhSRz4tInqqGMMOcYKyIA6G/6/22097NYpwq5mPmrvojH7hVROJE5LPAVIzCiMfMfVQBAcc6GcgdOg1jVdSLcW74/gGem5vngEki8gVHtjgROUW6HQsqibyG7wCNzuR/koh4ReQ4ETnlAL+312uHObdGoFlEpgD93fjfAz4jIsliYktuPIDzGjFYRRJb/BvmT7sRqAMWYsb0B4WqbgE+DzyMmbS7DONq7B8i+f6IeUordWRceQCyNWEmhS/DDH9tA85xdj8ELAX+ISJNTrv93ZwPhD7bVtVWzFDdm44HztxDPI/e+DNmDuEVVa12lV8MbBCRZkfGq8NDQ4730RmDkKXP6+1c889gblz1Tr3nMIqmL1YBE5227gWuUNUa55xvxSiuOswT+tIBxPsZZu6vGtPnywY6n75wvv9C4GqMFVZB98Q+wO+Aac41XOwMnV2GmZfZ4cjwKMaKPhD6unb/hemDJuC3wF/6aeNBzPxRJfAHjAPKYM9rxCCRQ6IWi+VIRURWAb9S1cd62Xc9ZlL49MMumGXEYy0Si+UIRUTOEpFCZ2jrOuAEDsEysFj6wnptWSxHLpMxw1GpGE+zK5y5OItlSLFDWxaLxWI5JOzQlsVisVgOCatILDGFiJwmItscz6UF0ZZnpCImh9r5zuc7ReTRwdQ9iO85Q0S2HKycliMDO0diiTXuBn6hqg9FW5AjBVU9kHiffhERxQTifeS0/QZmLsZyFGMtEkusMRaTyHI/xBATv1mxqcctli5i4k9psQCIyMeYCOVnnaGtBCcN970i8iYmd9cEMSnClzqptz8SkS+52rhLTMr0J8SkPF8vIpNE5A4xaef3iEifUdkiMkZEFolJP14jIr9wyntLL+8Rke+KyC6n7T+KSIZTP9GRocYJlFstIgWutrY78u0Qkc/1IkexmAXQsl1lM8WshhknJuvBK0771WLSr2f2cU4Rqyo6kdS7nGP/u0fdPlOki0g47f77zvW5SpwU8q7jpzrXrF5Mevt5rn39LjNgGblYRWKJGVT1GGA3zsJfqhqOwv4CcBMmNcUuTMTxXkxCwSuAH4pr7QxMVPOfMMkC1wHLMb/1UZihs1/39v1iklI+53zHOKf+064qczDpyPMxkd/XO69zMAowFfiFU/c6TCT1GExK9a8AbWLyaf0ck/8rDTgVk0ajZ1+UYdKcXO4qvhZYqKqdmNxO9zl9MNX5nrt6O68e5zgNkyvqC86xOZgU+2GCmFTyucAngPOArzkyhfNlnehcn4iIbjFpWp7FpPrJx2SOflJE3ENf12CyHmdh0sjfO5DMltjHKhLLSOBxVd2gqgFM0rvTge+oaruqvodJf/EFV/03VHW5U/9vmEzF9zs34KeBcX08vc/G3FxvU9UWp/0Vrv1lqvqwqgZUtQ2zoNJPVXW7qjZjUpVf7Qx7dWJu0seqalBV16pqo9NOCDhORJJUtVxVex3Kw+R6uga6EjJe7ZShqh+p6kuq2qGqVZhstIPJy3YF8Jyqvu4o6v+hO4szjpwrnXPciVG6g833NhejTO930rS8glHM17jqLFLVd5xr8yQmjYllhGMViWUk4E75XQzUOnmKwuwiMlV+z3Tk1b2knU9lf8YAu5yb3EByhGXZ5drehXFgKcBYRMuBp0WkTER+LCJxqtqCWYfiK5glA54Xk/ivNxYCnxCRYkziQMVJhS4i+SLytJiVNBuBJzBWxEAUu8/DkacmvO0MAz4nZoXARkxizsG029W2k4gyTM9r09cyA5YRjFUklpGAO2q2DMgWkTRXWQm9r1tyoOwBSvqZSO8ZvRuRxt2RIwBUqmqnqv6vqk7DDF9diknKiWMtXYBJyLkZk/hv/y9TrccME12JGdb6s2u9kPsceU5wUpl/nsGlaC/HlU5ezLohOa79B5IivSdlwJgeDhFDdW0sMYxVJJYRharuwaRJv8+Z0D4Bk+H2yf6PHBTvYG6094tIitP+af3U/zPwTREZLyKpmKf3v6hqQETOEZHjnXmXRsxQV1BECsSss56CycTbTP/p45/CKKDLiVwTI805tl5ERgG3DfIcFwKXisjpziT63UTeBwZKkd4zZbubVZj1N77tOAScjZmverqP+pYjBKtILCORazCT4WXA3zFLk750qI260o8fi5n034sZhuqL32OGsF7HpCtvx0wwg5nLWYi5KW8C/oUZfvJg1g0pw6xvfxbOZHYfLMWkdq9U1fdd5f+LWeO7AXgeWDTIc9wAfB2jlMoxaeH3uqoMlCL9LuAPjlfWlT3a9gPzMItBVWOWkf43Vd08GNksIxeba8tisVgsh4S1SCwWi8VySFhFYrFYLJZDwioSi8VisRwSVpFYLBaL5ZA4KhLP5ebm6rhx46IthsVisYwo1q5dW62qeQPVOyoUybhx41izZk20xbBYLJYRhYjsGriWHdqyWCwWyyFiFYnFYrFYDgmrSCwWi8VySFhFYrFYLJZDwioSi8VisRwSVpFYLBaL5ZCwisRisVgsh4RVJBaLxWI5JKwisVgsFsshYRWJxWKxWA6JYVUkInKxiGwRkY9E5PZe9j8oIu85r60iUu/aF3TtW+oqHy8iq0Rkm4j8xVku1GKxWCxRYtgUibNW9SOYZTenAdeIyDR3HVX9pqrOUNUZwMNELhfaFt6nqvNc5T8CHlTViZhlQm8crnOwWCwWy8AMp0UyG/hIVbc7azk/Dczvp/41wJ/7a1BEBDgXsxY2wB+ABUMgq8VisVgOkuFUJKOAPa7tvU7ZfojIWGA88IqrOFFE1ojIShEJK4scoF5VA4No8ybn+DVVVVWHch4Wi8Vi6YfhTCMvvZRpH3WvBhaqatBVVqKqZSIyAXhFRNYDjYNtU1V/A/wGYNasWX19r8VisVgOkeG0SPYCY1zbo4GyPupeTY9hLVUtc963A68BM4FqIFNEwgqwvzYtFovFchgYTkWyGpjoeFnFY5TF0p6VRGQykAW87SrLEpEE53MucBqwUVUVeBW4wql6HbBkGM/BYrFYLAMwbIrEmce4GVgObAL+qqobRORuEXF7YV0DPO0oiTBTgTUi8j5Gcdyvqhudfd8BviUiH2HmTH43XOdgsVgsloGRyPv3kcmsWbPULrVrsVgsB4aIrFXVWQPVOyrWbLdYYo3F60r5yfItlNW3UZyZxG0XTWbBzF4dEI9KbP/0T6z1j1UkFsthZvG6Uu5YtJ62TuOkWFrfxh2L1gPYmyW2fwYiFvvHKhKL5TDz/5ZtJLWzmglST7q0msIgvPzCFhZkzoyucDHAyy+sY0awI3IG1/ZPF+7+CaiX1TqFts4gP1m+xSoSi2XE09kOzRXQvA+aKqC50nmvgKZKs91cyWvt+/Am9jI32YnJ1XCU8zBAbxn0bP8Akf1TrynM6PgtAGX1bVGTySoSi6U/VKGj0VEEFa53R2G4y9ob9j9ePJCSB6kFkFYIRSfypw/a+bg9hX2aSQOpqJrY3dy0eB659qTDfIKxx9efepfqJv9+5bZ/DO7+CbjMtuLMpGiJZBWJ5SglFILW6v0th/2siX0Q6OVJz5sAaQWQWgh5k2D8mY6ycMrC7ym54PFGHJpZUspC1xg3QFKcl/suOR7G2TmACy4ZHzEHALZ/3PTVP7ddNDlqMllFYjmyCHQ4SsCxEtyf3e8tVRCRkcchIcNRAgUw+hRjRYStia73fEjMBOktC9DAhMexY8nrJpaw/dM/sdg/No7EMiwMqXuiKnQ0dc0xRFoMlZHDTG11vTQgZngprCDcFkP4PTXf7ItPPqTztliOJGwciSVqDNo9MRSCttoeE9KRE9NdyqKzdf8v8sZ3K4GcY2Dsqd2Wg3uYKSUPvPanbrEMF/bfZRlyfrJ8C/5OP8dIBeOlggKpI0/r4bnfwSava3hpH4QC+zeQkO5YCIUw6iSX5VAQOcyUlHXQw0sWi2XosIrEcui0VEPlh1C5ASo38MvWt5iUsJdE6YyoVh1Ih4YSowTyp+1vOYSVRXxKlE7EYrEcDFaRWAZPoAOqtjgKw1Ec+zaaoacwKfm0+4r4o/9CtoTG8JEWU6HZ1JBOQWYab3713OjJb7FYhgWrSCz7owqNpZEKo3IDVG/r9nTyJkD+FDj2fCiYbiyMgumQmk/ZulIeXLSetlDsuCdaLJbhwyqSo52OZti3KVJh7NsQGVyXUWKUxJRLzXvBdMg+ps8J7Fh0T7RYLMOHVSRHC6Eg1O2MVBiVG6BuR3ed+DQomAbHXe5YGdPNdmLGAX/dgpmjrOKwWI4SrCI5EmmtdSkLR3FUbe52oRWPsSiKToQZn3OsjGnG8vAM56KZFovlSMQqkpFMwA8123rMZWyEJtcy9sk5RlGcfH33sFTeFIiLXl4ei8VyZDGsikRELgYeArzAo6p6f4/9DwLnOJvJQL6qZorIDOCXQDoQBO5V1b84xzwOnAWEB/GvV9X3hvM8oo6qCczbb/J7K4QcF1tPnFEQ48/sVhgFx5l4DBtrYbFYhpFhUyQi4gUeAS4A9gKrRWSpa+11VPWbrvq3AOHFBlqBf1PVbSJSDKwVkeWqWu/sv01VFw6X7FHF3wpVmyLnMSo/jEz9kT7KKIpJFxplUTAdco4Fb1z05LZYLEctw2mRzAY+UtXtACLyNDAf2NhH/WuA7wOo6tZwoaqWicg+IA+o7+PYkUcoBPW79p/LqN0OOPnP4pKNW+3Ued0Ko2Caiei2WCyWGGE4FckoYI9rey8wp7eKIjIWGA+80su+2ZhlXD52Fd8rIt8DXgZuV9WOXo67CbgJoKSk5CBPoW8OKClhW70J3IsI5NsE/uawtJA93iiKE67sHprKHGcnvy0WS8wznIqkt4H5vlINXw0sVI3M6y0iRcCfgOtUNeQU3wFUYJTLb4DvAHfv90Wqv3H2M2vWrCFNcdxXUkIJBZg/pq1HTMZGaHDp08RMY110eUsdZwL7bFoQi8UyQhlORbIXGOPaHg2U9VH3auDr7gIRSQeeB76rqivD5apa7nzsEJHHgP8aMokHyU+Wb6GtM8gU2c3pnvVM9exmiuxm4rOlgJOE0OOD3ElQMhcKbuwemkorspPfFovliGI4FclqYKKIjAdKMcri2p6VRGQykAW87SqLB/4O/FFV/9ajfpGqlouIAAuAD4fvFHonvDbyOZ73+E7c01RoFltCY1gROJ4vf3aeURi5k8DX28LTFovFcmQxbIpEVQMicjOwHOP++3tV3SAidwNrVHWpU/Ua4GmNXGHrSuBMIEdErnfKwm6+T4pIHmbo7D3gK8N1Dn2RkRRHfVsny+Jm8FbCMXzQMBXFQ2ZSHF8+8cLDLY7FYrFElWGNI1HVF4AXepR9r8f2Xb0c9wTwRB9tRj19bHhk6oRR65l3zHKa/clsrJ3MzqbptLcfT2JiUXQFtFgslsOIjWw/COpbTRDgy7vPorylkOk5m5mes5nZhet4860nSEmZSHb26eRkn0Fm5my8XhtFbrFYjlysIjkIijOTKK1vo7kzlXcqTuadipMBZWZRHT/7dAe1tSsoLX2SPXsew+OJJzPjFLJzziAn+0xSUiYhdrLdYrEcQUjk1MSRyaxZs3TNmjVD1l5P918w623c95nju2JJgsF26uvfoab2DWpr36ClZRsA8fH55GSfTnb2GWRnn0Z8fM6QyWWxWCxDiYisVdVZA9WzFslBMJj1NrzeRHJyziQn50wA2tvLqa19k5ra16mqfoXyikWAkJY2nZzsM8jOPoOMjJl4PNbTy2KxjCysRRIFVIM0NW2gpuZ1amrfoLFxHapBvN4UsrLmkp19BjnZZ5CcPC7aoloslqMYa5HEMCJe0tNPID39BMaPv5lAoIm6urepqX2Dmpo3qK5+GYCkxBKyc8ykfVbWJ/D50qIsucViseyPVSQxgM+XRl7eheTlmRiU1tadztzKCioqllBa+pSjfGaaYbCcM0hPOw6TYNlisViiix3ainFCIT8NDe9RW2uGwZqaNgCKz5dJdvZpzvzK6TZ2xWKxDDmDHdqyimSE4ffXUFv7JrW1b1BTuwK/fx+AE7tyhit2JTHKkloslpGOVSQujiRF4kZVaWnZSk3t69TWrKC+4R1CIb8TuzLbiV05w8auxCAHtAzBUYjtn/45XP1jFYmL4VAksfhDDwbbnNiVFRGxKwnxBWRnn971io/PjqqcRzuDiUM6mrH90z+Hs3+s19Yw0td6JEBUf+hebxI5OWeRk3MWEI5dWeHErrxMecUzmNiV45ygyDOd2BW7RO/hIhQK8KtXVpGfWElGRiPJcW1d+5aveZc5RdOiKF1ssHzNRk7M9fdSbvsHIvsnEPKypvIk2jqD/GT5lqjdf6xFchCcdv8rlNa3cQE+PkU8HxLkQ4LUpsfxjzujnlOyV1SDNDZ9SG3N69TUrnDFrqSSlTW3KygyOXlstEUdkQSD7fj9++jo2EeHvwq/vwp/+LO7zF9D3+u7WSwHRktnMre+ej9g0qHvuP9TQ9q+tUiGkfB6JIKQhvAF4vEi0AgVP11DfEk6CSXpxI9Nw5eXjHiiPz8h4iUj/UQy0k9k/PhbCASaqK17y1gsNW9QXf1PIBy7coYTuzL3qI5dUVUCgUY6/Pvwd+zD7692PlfR4SgNv6MgAoGm/Y4X8RIfn0d8fC6JCUWkp59AQnw+D71ay+76JOr96bR0JoOa30dBeiJ/+fLcw32aMcdVv15JZWP7fuW2fwzu/gm5FqItzoxectgBFYmIzAU2qGqTs50GTFPVVcMtXKwSTtr4Dzr5B50kAVPwclpiItdnJ9G+sYbWNZUASKKP+JI0EkrSiB+bTvyYNDyJ0dffPl8a+XkXkZ93EapKW9vOrrmViorFlJY+iYiPjPSZXYolLe04REb+GvKqQfz+mi6l4PdXuSyJsKIwn0Oh/YdYPJ5EEuLziU/IIzVlMvHZp5vt+DwSEvKIj88nISGPuLjsXvvrnIbex7jvPPt4kpPtHMCNZ8fZ/umHvvrntosmR02mAYe2RGQdcFJ44Skx/4w1qnrSYZBvSDjcSRtVlUB1G/5dTfh3N9Kxq5HAvlYzoiEQV5BslEpJOvFj0/HlJMaUV5WJXVnXlXCyqcksQhkXl0V21mkm4WTO6SQmFEZZ0kiCwQ6jCPxVdDhWQ8SwUrjMXwOE9jve58t0FEFel6IwCiKXhIT8LgXh9aYe8vWKRWeNWML2T/+MOK8tEXlPVWf0KPtAVU84RBkPG7HgtRVqD+Df3a1Y/Lub0A6jiDwpPuLHpDvKJc1YLfGxE7UeGbvyBn5/FQApKZO65lYyM0+JiF357uL1/HnVHoKqeEW4Zs4Y7llw/AF/txleajLKwTWs5B5q6ugw1kMg0NhLCx5HETiWQnwe8Qnh97CiyCchIRePJ+Fgu8hiOSIZSkWyCHgN+KVT9DXgHFVdMAghLgYewiy1+6iq3t9j/4PAOc5mMpCvqpnOvuuA7zr77lHVPzjlJwOPA0mY1Rf/Qwc4iViMI9GQEtjXSsfuxi7LJVDlePB4IK4o1QyJOZaLNyshJqwWVaW5ZQu1tW9QW/MG9Q2rndiVBDIzZ5OTfQZPvFfIb95SIIT4GtFAOuDl83NLupSJahB/Z51jMbgUhGNN+LsURBWh0P7j5R5PQpeFEH4PDy91KYiEfOLjsmwqGYvlIBlKRZIP/Bw4FzM48zLwDVXdN8BxXmArcAGwF1gNXKOqG/uofwswU1W/KCLZwBpglvOda4GTVbVORN4B/gNYiVEkP1fVF/uTJRYVSW8EWzrx72nCv6sR/+5G/HuaUL8ZgvGkxZlJ/LDVMioNiYv+fEV37IpJONna+hEAdR2pbO6A8mAHyR4hnXjSPV6OyUwggXY8wWZ6H15Kj1QMvQw1JSTkD8nwUjSxQzf9Y/unf0bc0NYhCPAJ4C5VvcjZvgNAVe/ro/5bwPdV9SURuQY4W1W/7Oz7NcYqeg14VVWnOOUR9fpipCiSnmhQ6axscRRLEx27GwnWOE/nXiG+2Fgt8WOduZaM6A/NVDRs5I4l32R69g4mJYRI8SohhaZAHI1BaNIQDUFoCgqNIUF8maQljSEv9RiKM6cyPnMS4zPGU5BcMKIVRX8sXlfKHc+sJzEQItPxuknwefjG+ZM4b2p+lKWLPi9v2sfP/rmVjkD3g4btn27c/RMEdhOKekBin4pERL6tqj8WkYfpxfFdVW8dQIArgItV9d+d7S8Ac1T15l7qjsVYGKNVNSgi/wUkquo9zv7/AdowiuR+VT3fKT8D+I6qXtpLmzcBNwGUlJScvGvXrv7EHTEEm/xdSsW/qxH/3mZw/nDejPiuSfyEsenEFaUgvsNjtYQ0xMKtC3no3Ydo6GjGX3MmndVnkxbnp8mfiuLBK8Lmey5gT9MedjTsYEfjDvPuvJo7m7vaS/YlMz5jfOQrfTwl6SXEe2N/8S/tDBFs6CBQ306wvoNgfQeBug6CDR3rTX45AAAgAElEQVTs3F5HdggSODIVpeXw0YjySYzr+ajMJN68fWjj2IYijmST836wj/K9/Uv6Mn+uBhaqatgNqq9jB92mqv4G+A0Yi6R/UUcO3rR4kqbnkDTdLNGrgRCd5S3dimV3E20fVJvKPg/xo1KJH5ve5X7sTRv6m/Cmmk3cs/IePqj+gFkFs0hruZKlm41ya/R3T8BfM2cMcd44JmROYELmhIg2VJXqtupuxdK4g+3121lTuYbntj/XVc8jHkanjt5PyUzImEBGQsaQn1tvqCqh1kC3gnAri/oOgvXthJo69zvOkxaPLyuBjaEAFYSoJEQ9GvEDfuTaEeMMOWx8/al3+9xn+yeyfwKu8nB8WzToU5Go6rPOPMdxqnrbQbS9Fxjj2h4NlPVR92rg6z2OPbvHsa855aMH2eZRgfg8xI8xnl6c5qwX39ARMYnf/GYpza+b25U3OzFiEj+uMAXxHtyTcbO/mUfee4SnNj9FZkIm955+L5dNuAwRId17YF5bIkJech55yXnMLpodsa+1s5WdjTsjrJcdjTt4u+xt/K44j+zEbMalj9tPyRSnFOP1DH7CXYMhgo1+gnUdBBo6CNa1RyiJYH1H19xVFz4PvswEvFkJxE3OxpeViDczAW9mginPSOiyDn9z/yuU1nfs972jMpNIPiFv0HIeqWx9IY7SXm6Ktn8MffVPNAMSBzPZ/oqqHrC9JCI+zGT7eUApZrL9WlXd0KPeZGA5MN4Vq5KNmWAPP368i5lsrxWR1cAtwCrMZPvDqvpCf7KM1DmSoUI7Q/jLmrsm8Tt2NRFqMjdgiXMUkROJH1+Sjjel/9xbqsryncv58eofU91WzWcnfZZbT7r1sFkEYYKhIGUtZZEKxnnVddR11Yv3xDM2YywTMiYwPmM8xySOZzxjKAjk4mvW7mGnsKJo9O9n53pS4rqVQmYC3sxEfFkJXcrCkxI36Dkdm5Swf2z/9M9ITdq4TkSWAn8DWsKFqrqov4NUNSAiN2OUhBf4vapuEJG7MQGNS52q1wBPu114HYXxA4zyAbhbVWudz1+l2/33Redl6QeJ85Aw1sybgFEEwfqOiEn8ptf3dDlR+XKTuibxE8am48vvTvOyq3EX9668l7fL32Zq9lQeOuchjs878PiQocDr8TImbQxj0sZw5ugzzbmFlFCTn7p91eyrKKV+Xw0dtS1IZYCEljiyOlJJDSUD9TRTD0BQgrQm+wmleYgrTiLthBzS8rK6rYqMhCGN6wn/2a1XUu/Y/umfWOyfwVgkj/VSrKr6xeERaeg52i2SwRDyB+nc2xwx1xJqMeP8kuDFNyaF9Qnb+HPzInamlvPFWf/O1ZOvPqAho6GSMzwf4Z6fCE9kBxs6IBj5m5ZEX5f1IOlxNCa1UhlXwy5K2Rr6mA3tW9jeuJ22QPdwQVpcGuMzxjMuI3KobEzaGOJstmTLUcJQxpGcpqpvDlQWy1hFcuCoKsGadjp2N7J741bqt1dS3JqHFzPO78tP7o5pGZuOLzcpIjnlwUS2qyqhls79hpoC9d2fQy2ByIMEvOnOEFNWeOgpMWIYajC5zVSVytbK/eZhdjTsYF9rd8iUT3yMThsdMckfVjjp8emD7l8bJ2EZCQylInm3Z16t3spiGatIDo7Klkp+tPpHvLTrJcalj+O/Z97BjMDU7hxiu5vQNnNjlySf8QwrSefJvdX8fFM5PacD/232GL531kSjGOp6KgkzmU0gchJb4j3diiErPHndPZHtTU84aGeBwdLsb2ZX4y62N2yPUDS7mnYRCHUrttyk3C43ZbcVU5hSiMeVvHHxulJuW/g+nS7LKc4r/OSKE60ycbCKtn9GTECiE1B4KvAN4EHXrnTg06p64lAIejiwiuTACIQCPLXpKR557xGCGuRLx3+JG467Yb/4DQ2Fk1M6cy3h5JRAEGVnKECTv5lMbxxZnnjSPHF4ekxISwJ4ktwvwZME4mxLHDEbmBjUIDVt1VS0VHS/Wisob6mgtbNrOpEEbwIFyQUUpBRQmFLI8++20dqWhnam4/ckUpWUSU1SBmmpSaz73oVRPKPYwE62908sTrb3p0jOwrjgfgX4lWtXE/Csqm4bAjkPC1aRDJ739r3HD1b+gK11Wzl91OncOedOxqSNGfhAh2BDKz/4rz9xdlsTY+PT8CRlo221hNpq0dZaQm015r21Fm2vg1Bg4EaPAkJAXarQkOWjNsNLXYaXukxv1+faDC+tSQIxqlSHkurmDoKh/e9LXo+Qmxr97A3Rxt0/Gkqidfu3gBgNSFTVfwH/EpHHVXWXiKSoaktf9S0jm/r2en727s94Ztsz5Cfn89Ozf8r5JecPyhpQVdrXr6dh8RIan3+eqxoaqE1I48nRM3mncBqdXh+kpuNJS+dvX7n2MJxN7OIPdvC5x5cjvno88XUkaBO5zR3kNfvJa+rgOI+QV9VC8uZWvD2G+ToTfLRmJ9OaY14t2Sldn1uzk2nLSiLkG/kJKp9+Z0+vUcZB4Mwpg3+oOVKJ6B/tdvyIyYBEF8Ui8iKQCpSIyInAl1X1a8MrmuVwENIQSz5awk/X/pQmfxPXTbuOr874KilxKQMe21leTsPSZ2lYsgT/9u1IQgJp553HkoITeaAmk1APj67Pzy0h+aTouArHCslA6QuN1Le5It8zzSszKY73vm+GtlSVYG0tnWXldJaXESgvp7OszNkup/PDcoI12yMbF8GXl0dcURFxo4rxFRURV1RMXHGRKSsqwpOREbNDhWFeev2VPgMS7zo1NpeyPpz01T8xvUIi8DPgImApgKq+LyJnDqtUlsPC1rqt3LPyHtbtW8eMvBl8d+53mZzd/yproZYWGv/xEg1LltC6ahWokjTrZApvuJv0iy/Gm5bG14CyIVqP5EjkrnnTue1v79PpGr6J8wh3zZvetS0i+HJy8OXkkHT8cb22E2pvJ1BRYRRLWMGUl9FZVkb7ho10/vNl1B+5wqMkJ3cplbjibiXjC2/n5yPx0c1ldttFk2NuBcBYIhb7ZzBeW6tUdY6IrFPVmU7Z+3ayfeTS2tnKL9//JX/a+CfS4tP41snfYv6x8yM8i9xoMEjrqlU0LFlC4z9eQtvaiCspIWP+PDLmzSN+jB1uOFAOh9dN71aNY9mUG8UTrKmJPMhl1fiKHeUSBavGem31z4jx2nI1tBD4KfALYC5wKzBLVa8eCkEPB1aRGFSVl3e/zP3v3E9layWXT7ycb5z0DTITM3ut3/HRRzQsWULD0mcJVFbiSUsj/ZJLyFgwn6SZM2N+iMQyMH1ZNYHycjpLjcIZiVaNZWgYyhQpX8GscjgKkzTxH0QmWLSMAPY07eG+VffxRukbTMqaxANnPcCM/Bn71QvU1tL4/As0LF5M+4YN4PWSesYZZNxxO6nnnIMnwXrNHEl4EhOJHzeO+HHjet3fp1XjzNm0b9o0LFaNtUj6J9b6Z9gWtooljmaLxB/089iHj/Hb9b/FK16+NuNrfG7q5/B5up8hQn4/za++RsOSJTS//joEAiRMm0rm/Pmkf+pT+HJzo3gGllinX6vG2daOyGzHEVaN4xwQtmpeq/Nw++sVNAW7FY2NI+lmRMWRuBoaj8m2Ow6XBaOq8w5RxsPG0apIVpav5N6V97KzcScXjL2Ab5/ybQpTCgHHZff996lfsoTGF14k1NCANy+XjMvmkTF/PomTJ0VZesuRQr9WjWPZ9LRqQgi1iWk0JKSizjJEcV4PkwpTo3EKMcXWimY6g8Y1vNWXwHfOMA60MRlH4mIx8DvgWXpbZNsSc1S3VfPj1T/mxR0vMjp1NP933v9xxugzAPDvLaXx2aU0LF6Cf9cuJDGRtPPPJ2P+fFI+MRfxDeYnYbEMngP1QPvmz5eR21ZPfms9Gf7miHrTCwoOh8gxTXltZdfnNl/3UHOsx5G0q+rPh10SyyETDAX5y5a/8PC6h+kIdvCVE7/CjcfdSFx7gPpnFhmX3XfeASD5lFPIuekm0i66EG+qfcqzRBf3XM2Gf7X1GUdywxA/cY9EHr1/ZMaRPCQi38dMsncNdKpq3+thWg47H1Z/yN1v382m2k3MLZrLnbNuJ29jBTW3/w9N//wn2t5O/Nix5P3HraRfNo/40Xas2RKbxGKcRCwRi/0zGEVyPPAF4Fy6h7bU2bZEmYaOBh5e9zB/3fJXcpNy+VnJtzhudTWNP7iBPVVVeNLTyVgwn4z580maMcO67FpinlhcuCmWiMX+Gcxk+2bgBFX191sxhjkSJ9tVlee2P8cDax4gVFvHLVUzOOndRjo3bwGfj9QzzyRj/nxSzzkbTxR8+hevK6Xk8k/hDwT5z689FPUfusViOXCGcrL9fUw2oH0DVexFiIsxMShe4FFVvb+XOlcCd2GsnPdV9VoROYfI1PVTgKtVdbGIPA6cBTQ4+65X1fcOVLaRzPb67dy34m5YsZpvbU1l4pYgElyNd/p0su+8k/RLP4UvOztq8oXdEx8LGNO7tL6NOxatB7DKxDJ4zj7bvL/2WjSliF1iqH8Go0gKgM0isprIOZJ+3X9FxAs8AlyACWRcLSJLVXWjq85E4A7gNFWtE5F8p+1XgRlOnWzgI8wcTZjbVHXhIGQ/omjtbOWvz/yApiXP8uVNIVLaFV9+IhlfvJKMefNImDgx2iICxuRu6wxSU5hL1ZgiJnqrqAkk88CyTVaRuImhG4HFcigMRpF8/yDbng18pKrbAUTkaWA+sNFV50vAI6paB6CqvVk9VwAvqmrrQcox4vHv3cv7f3yItueWMac2QCDeS8oFF5L/mc+SMncu4o2t1OHl9S3M9JWx+pIzQeE0z04Agu3Cr371EUVFRV2vgoIC4m06DYtlRDOgInHWJTkYRgF7XNt7gTk96kwCEJE3McNfd6nqsh51rsbk+nJzr4h8D3gZuF1VO3rsR0RuAm4CKCkpOchTiB7BpiYaly2jatHfCK5bTypQOSGZ9Ju+yPFX3IQ3deA079Ggrq6OeUnbyNRGRm3dydSVH/DVq75LjrQwNqmTiclxbN68mXXr1gEmxiA3N5fCwsIu5VJYWEhSUvRcGS0Wy4ExnNFnvbkH9ZzZ9wETMSsxjgbeEJHjVLUeQESKMF5jy13H3AFUAPHAb4DvAHfv90Wqv3H2M2vWrBGRB0YDAVreeouGxUtoevlltKOD8mxhxTnxTPjsdVx11i3EeeMGbihKbNiwgaVLl5LtDbHCfyx3r3gGgCZNJOBL4RuXmhQOqkpjYyPl5eVdr507d7J+/fqutrKysiKUS1FREak23sViiUmGU5HsBdz5xUcDZb3UWamqncAOEdmCUSyrnf1XAn939gOgquXOxw4ReQz4r+EQ/nDSvmULDYuX0PDcswSrqtH0FFbOTGLp5AAls8/h9jl3UJxaHG0x+8Tv97N8+XLWrl3LqFGjuPzyyzlhVxvxTzyAPxBkVA/3RBEhIyODjIwMpkyZ0tVOc3MzFRUVEQpm06ZNXfvT0tK6LJawcskYAQs1WSxHOoNSJCKSBJSo6pYDaHs1MNHJ1VWKGaLquc7qYuAa4HERycUMdbmXfbsGY4G4ZSlS1XIxd48FwIcHIFPMEKiqouG552lYsoSOzZvB5yP+jE/wylQ/v05ZQ35GDnfMuY+zx5wdbVH7pbKykoULF1JVVcVpp53GOeecg8/nY0E2UGLS0w82/09qairHHnssxx57bFdZe3v7fspl27ZthN3Wk5KS9lMu2dnZeDy9r61isViGngEViYhcBjyAGUoaLyIzgLsH8tpS1YCI3IwZlvICv1fVDSJyN7BGVZc6+y4UkY2YJZlvU9Ua53vHYSyannM0T4pIHmbo7D1MmvsRQai9neZXXqF+8WJa3nwLgkESjz+e/O/eyWuTA/z0o0dpDbRy/fQvcdMJN5Hki915AlVl7bXXsuzYY0kIBvn8pk0c+9prcO+93ZX+5Vy6sHdSX/TjtZSYmMi4ceMY50pz7vf7qaysjFAwq1atIhg07sbx8fEUFhZGKJe8vDy8MeaUYLEcKQwmIHEtJor9NdcKiR+o6gmHQb4hIZoBiapK29q1ZnXBF5cRam7GV1hIxrx5ZMyfx/ZMPz9Y+QPWV6/nlMJT+O6c7zIhc0JUZB0sbW1tLF26lE2bNnFMbS2f3rSJ1M7O/SuGFclZZ/Xf4BC4vwYCAaqqqiKUS0VFBZ2OXF6vl4KCggjrpaCggLi4KM45He3uvwM9YBzG309MEgP9M5QBiQFVbbDj0AeGf/duGpYspWHJEjr37kWSk0m/4AIyFswnefZsWoJtPPjeL/jzm38mMyGTH57+Qy6dcGnMj/fv3r2bZ555hqamJs4//3xOPfXUvoeRDuON0ufzdVkfM2fOBCAUClFTU9OlVMrLy9mwYQNr164FzFxNXl5ehHIpLCwkMTFxaIQa7I3gECw2iyUWGIwi+VBErgW8TgDhrcBbwytW7NPbCmWXHZNG44vLaFiyhLZ33wURkufOIe+Wm0k7/3w8KSmoKst2LuMnq39CdVs1V06+kltm3kJGQka0T6lfQqEQK1as4NVXXyUjI4MvfvGLjB49Otpi9YvH4yEvL4+8vDxOOMEY0KpKfX19hHL5+OOPef/997uOy87OjnBFLioqIiUlNt2tRzQDKcij3WIbQf0zGEVyC/DfmKj2pzDzGvcMp1CxjnuFMm8oSPHmtVT/87dsrtyAp7OT+AkTyPvWt8i47FLiioq6jtvZsJN7V93LyvKVTMuZxs/P/TnH5fa+PkMs0djYyKJFi9i5cyfTp0/nsssuG7qn9sOMiJCVlUVWVhbTpk3rKm9qaooYEistLWXDhg1d+9PT0yNckQsLC0lPT+/fghxBNwKL5VAYTEBiK0aR/PfwizMyCKcAuXDXO1y/8QWyOpppiE/m1WNO5cYf3EzicdMjbjDtgXYeXf8ov//w9yR4E7hj9h1cNfkqvJ7Yn/zdunUrixcvprOzk3nz5jFz5syYH347GNLS0khLS2PSpO6VIVtbW7uslvD7li3djovJycn7KZesrCzrMWY56hiM19ZLwGddQYJZwNOqetFwCxerhFcia45LYkP2eF4uOZk1BVMIenzc3GMFuBWlK/jhqh+yp2kPnxz/SW475TZyk2J/DfRAIMA///lPVq5cSUFBAVdccQV5eXnRFuuwkpyczIQJE5gwodv5oaOjg8rKygjr5a233iIUMissJCQk7Beln5ubu5/H2OJ1pZTsrjfZke9/xWZH7oHtn/6Jtf4ZzNBWbliJALiTKx6tFGcmUVrfxq2vPQnAvXOuA8wKbmEqWyr50eof8dKulxiXPo7fXvhb5hbNjYq8B0pNTQ0LFy6kvLycU045hQsvvDC63k0xREJCAiUlJRFpdwKBAPv27YtQLmvWrCEQCADGESDsMVZUVMSWRi/3vlLG72x25F6x2aP7Jxb7ZzCKJCQiJaq6G0BExrJ/qpOjivAKZW7CK5QFQgGe3PQk//fe/xHUILfMvIXrp19PvHdkJCZ8//33ef755/F4PFx11VVMnTo12iLFPD6fj+LiYoqLu7MPBIPBLo+x8Gv9+vWE3dAv9whvzj+P5MZmzor7GIBlz35M50dH9TMaAC9v2sdsgrx39mwA2z89cPeP13lYaesM8pPlW2Jakfw3sEJEwoGBZ+IkQzxaCV+s+Ce9ESlAxo2q4qrnbmVr3VbOGHUGd8y5gzFpYwZoLTbo6Ojg+eef54MPPqCkpITLL7+cjIzY9iSLZbxeL/n5+eTn53PiiScCxvOtvr6ezzzwPNmeVs5tK6c5K4NscRJbB6CiItRPq0cHSYEWkgSasjNRIFtazI4AVJQH+z32aCDcP43Zmfhc8Vu9reN+uBjMZPsyETkJmIuJJv+mqlYPu2QjiJC0sHjPg6z9YDkFyQX87OyfcW7JuSNmUrqsrIyFCxdSV1fHWWedxZlnnjk0UeDWGykCj8dDdnY2nemjeLe+jW//4xcAXH2tWe9tVGYSD95y9K5gHQoGqdq1gy8/sJDC9nISa7fgT/AxurzbwcF/IEmajlDcTvfeQBDSzHS1N4r3m8EmbUwAap3600QEVX19+MSKbcJjlL8LBnnrJGjMvYc1te2cnnc5P73w2yTHJUdbxEGhqqxcuZKXXnqJlJQUrrvuuohUJJbhob+h0aOJjtZWyrdtpnTLJsq2bKR82xY6O9o5A2jypvJh9hRq4rNRVyLxb188pe8GjxJ+vGxz1+eAdD/wBQfIUjKcDMZr60fAVcAGIGx3K3DUKpKw++/i8+DFsyDUmk9HxQLWV4wn+VMjQ4m0tLSwePFitm3bxqRJk1iwYAHJySND9pFOeGj0P1Meoqy+bb/syEcqjdVVlG7ZSNmWjZRu2UT1rp2ohhDxkDt2HNPPPo9Rk6dx88v1fNS6/61pVGYScxYcvRZbmIrNr/Q6jOV29jncDMYiWQBM7m3xqKOVsPvvmWugoAYennoT4KGsI3pjlAfCjh07eOaZZ2hra+OSSy5h9uzZI2YY7khhwcxRR7TiCIWCVO/eRenmDY7FsYmmmioA4hISKZo4mTmfuYpRU6ZRdOxkElwPMTcndwf8hjkaLba+CFu0sdQ/g1Ek24E4XOu1H+2E3X9z6yF3HTw81dNVHssEg0Fee+013njjDXJycvjc5z5HkSvy3mI5WPztbZRv20Lp5o2Ubd1E+bbN+NvMg1Vqdg7Fk6cxa/KnGTV5Gnljx+PpZw4urGB7piA6khXvgRCL/TOY7L/PACdilrXtUiaqeuvwijZ0HHT23z6S6VU3d7C9qoXZu80498oxx+ERYUJeCrmpCfsfEAOTzvX19TzzzDPs2bOHGTNm8MlPftKulW45aJpqqynbsonSzRsp3bKRql070FAIRMgbM5biydMYNXkqo6ZMJy03z1q8I5ShzP671HlZHLqUxW7zFu/zUpKd1LsSiQE2btzI0qVLCYVCXH755Rx//PHD/p29JbW0T5TdjKT+CYWC1OzZTemWTZRu3kDZ1k00Vu0DwJeQQNGxk5mz4LMUT55G8aQpJCQfeoLLkdQ/0SDW+mdAi+RIYNjWI4nxpHudnZ0sW7aMtWvXUlxczBVXXEF2dvawf687qWWYpDgv933meHszIPb7p7O9nfKPtppJ8a1mfsPfZmJdUrKyGTVpapfFkTduAl7f0K7YHev9E20OZ/8M1iIZzNDWROA+YBrQlfJVVQdcfUlELgYewqyQ+Kiq3t9LnSuBuzCeYO+r6rVOeRAI+0juDq/I6Czd+zSQDbwLfEFV/f3JcTQqkn379rFw4UL27dvHqaeeyrnnnotviP/wfXHq/a+wxxsiODaVUFY8Ye9NQUiMswkN2ztDaC/JIaLVP6qgGkJDIVQV1VBX7grxeBCRrndEGO5Bqljrn1gjon86lcR/VQDGa2uwy1oPlqEc2noM+D7wIHAOcAMM/FsSES/wCHABsBdYLSJLVXWjq85EzJrsp/WSw6tNVWf00vSPgAdV9WkR+RVwI/DLQZzHUYGqsnbtWpYtW0ZCQgKf//znI9ZAH05aAkH+WlnHjulpaGocdATxlrZCyPzoBbjhzGMOiyyxzG9e/7jXHEOHpX9UaWtupLm2hubaGppqa+hoNZHjHo+XlKws0rJzSM3OITUrB2/c4Z9Hi2r/jAAi+ifY3VNlsRzZDiSp6ssiIqq6C7hLRN7AKJf+mA18pKrbAUTkaWA+sNFV50vAI6paB6Cq+/prUMyM3bnAtU7RHzDWjFUkmCVwn332WTZu3MiECRP49Kc/TVpa2rB/7662Dn5fWs2fy2toDIRIQAh9UIunog1x3RFGZSbxvWOL+27oKGH5ws19xgEMdf90+juo+GirmRjfYjyqOlpayAWSMzIZNXkaxZOnMmryNPLHT8Dri35yzsPZPyORvvonml6jg1Ek7SLiAbaJyM1AKTCYzGmjgD2u7b3AnB51JgGIyJuY4a+7VHWZsy9RRNYAAeB+VV0M5AD1qhpwtWkHTYE9e/awcOHCwS2BOwSoKm/WN/Po3iqWVzfiEbg0L5Mvjc5jz8d13PlONW0uJRJtP/dYYjjjAFrq67qVxpZNVO74mFDQ/F2yR41h0tzTu5RHZkFRTHpTxWKcRCwRi/0zGEXyDSAZs8TuDzAWwXWDOK63X2hPi9UHTATOxqSQeUNEjnPS1peoapmITABeEZH1QOMg2jRfLnITTnJJd8rvI42eS+DecMMNjBkzfIki24IhFlXW8ejeKja1tJMd5+XWsQVcV5xDcaIZBpl1UgoiElNeJbHEUMUBaChEbVkppVs2dCmP+opyALxxcRQeM5GTL11gFMekKSSlpQ/5uQwHsRgnEUvEYv8Mm9eWiHwCY2Fc5GzfAaCq97nq/ApYqaqPO9svA7er6uoebT0OPAc8A1QBhaoa6PkdfXGkTrY3NTWxaNEiduzYMexL4Ja2+3m8tJonymqoCwSZlpLIv4/J49P5WSR57QTo4SDg91OxfZsJ+tuykbKtm2lvbgIgKS3dFbsxjfzxx+Kza8hYDpEhm2wXkVmYVPJj3fVV9YQBDl0NTHS8rEqBq+me2wizGLgGeFxEcjFDXdudVRhbVbXDKT8N+LGqqoi8ClyB8dy6Dlgy0DkciWzbto2///3v+P3+YVsCV1VZ3dDCb/dW80J1PapwSV4GN47K4xOZKf1+X6z5uccag+mf1saGLkujdMtG9m3/iKCz/kRW8WiOPWWuM78xnayi4pgcprIcHQxmaOtJ4DaMK+6gF0twLIabgeWY+Y/fq+oGEbkbWKOqS519F4rIRiAI3KaqNSJyKvBrEQkBHswcSXiS/jvA0yJyD7AO+N1gZRpyomCJBAIBXn75Zd5++23y8/O54ooryM8f2sV+OkIhluyr59G9VXzQ1EaGz8uXR+dz/agcSpIGDrrs6eceCyu4xRK99s8zH+CvqWCqt8axODZRV14KgNfno2DCRGZeMq9rfiM53a4VY4kdBgANKWcAAB0nSURBVBNHskJVTz9M8gwLwzG0FY0n7uFeAreyo5M/lFXzx9IaqjsDTEpO5MZROXw6N51EDRIMBAgGAoQCAYKBzl63Q4EAt/3lXepb2vFoEI92P3tkJcfz3UunDZm8I5V7nttIXasJfUoKtlHcUUFRewVJoXYAElPTujypiidPpXDCRHw2nY0lCgxlQOJ5mOGnnrm2Fh2qkIeLoVYkhxpZqqqEgkHnBhx5Ew5vd38OEAp0sm3XLlZ9sAGPCLOmTKQwK6PfY8LH9XWzd9fZmZrFm+OO48PRxxIUDxNLP+LkD1dRsmcbGrQr0g03db4MyhMLqUgs5I93XE128ShkGD3uLJbBMpQBiTcAUzAZgN3rkYwYRTLUhNcjObblYyY3b8WjIbwaZNXDf6elKGXAG3d4nHswqHhoLywhkJmLt7WJuNIdrF+/kvW9VRbB54vD4/PhdV4eX5zrc7g8DklMZGNeCa8VHcP21GwSgwHOqy/nwqZKigngPX4a3pkn4PH23lZ/bd/4p3VUNHcSFA9K9w2xID2RhV/9xKFfgBHOFb98m8pGY334PXG0e43//6jMJHJGj4ylmS0WN4NRJCeq6vBn+RtBhCNIE4IdpAWaCOElKB7agx4SU1IjbqqRN1nXzdcbLt+/jtdRBvXNLby+Zi2BpmZOPuF4Zp80k7j4eFf9yGM9noGXx632B3iirJrHS2uo8HcyPimee0bncVVhNmm+IVheF7jp06m9Wmxfn3c8GfmFQ/IdI5mvz5sdc3EAFsuhMBhFslJEprlTmxzthNcj2ZA+jQ3p3WP+ozKTeHAIct2oKqtWreKl11eQnJzMddddx/jx4w+pzQ+bWnl0bzV/31dHR0g5OyuNB6aM4dzsNDxD7O0Ti37usYTtH8uRxmDmSDYBxwA7MHMkAugg3H9jhlibI+mPlpYWlixZwtatW5k0aRLz588nJeXg0nIHQsrymgZ+u6eKlQ0tJHk8XFmYxY2j85iUMjzxJhaL5chhKOdILh4CeY4ohuuJcseOHSxatIjW1lYuvvhi5syZc1CxAXWdAZ4qr+X3e6so/f/t3Xt0VeWd//H3J/eQQA6BIJAEuRipVhQ02jo6nVZUcKrVqj/rrcr4sy5njWM7nbKqM+3U2vqrna7fdLVTf/0N9dZ2bG3xSuso2nprHa2AgggWRbwkgAKBcAm5nnznj71PcnJITg45OTkn8H2tdVb22bfznCewv9nP8+zn295JbUkR35g1lcumVBIpHJkZgJ1zh4+kV5Vwjq3HzOy4ESrPqDGcObej0SjPPfcczz//PBMmTODyyy8fUgrcDS1t3NW4naUf7KS12/iLSDnfrqvm7IkV5PvDas65DEkaSMysW9IaSdPM7P2RKtThJDEF7jnnnENxceqZFrvN+F3THu5s3M7zu/ZRkicuPGI819ZUcWx5bueQd84dGlJp55gCrJP0MtASWxlLNOWGLj4F7oUXXsjxx6fe7bS3K8r9W3dy1+btvNvawZTiQv5p5hSumDKBCUXefOWcGzmpXHG+mfFSHGY6OztZvnw5K1euPOgUuG/vb+Puxh3c/8FOWqLdnDyujJtnTuGvJ0YozPPmK+fcyBs0kJjZc5KOAE4OV708WAIqN7D4FLinnnoq8+fPHzQFrpnx7M693Nm4g9/v3EOhxPmTIlxbU8XccWNGqOTOOde/VGb/vQT4HvAswdDff5e02MweyHDZDilmxiuvvMLjjz9OUVERV1xxBXV1dUmPaemKsvTDXdzVuJ239rdTVVTAV6ZP5qqpE5hU7FOEO+dyQypNW/8MnBy7C5FUBfwO8ECSooNNgfteazv3bN7BL8LUtSeMLeVHx0zjM5MiFPkcTM65HJNKIMlLaMpqAvxqlqKGhgYefPBBdu/ezfz58znttNP6TYEbS117V+MOlu/Y3ZO69tqaKk4aN8ZzTTjnclYqgeQJScuBX4bvPwf8V+aKdGjo7u7mhRde4Omnn6aiooJrrrmm3xS4A6aurZ7AlGKfOtw5l/sGDCSSis2s3cwWS7oQOJ2gj2SJmT08YiUchfbu3cvDDz/Mpk2bOPbYYznvvPMoLe37TEd/qWv/7SO1nrrWOTfqJLsjeRE4UdLPzezzHMbTxh+M+BS45513HieeeGJPs1Q6qWudcy5XJQskRZKuBv4ivCPpI5XEVpIWAj8gSLV7p5nd3s8+lwC3EOQ4WWNml0uaC/wYGEeQgvc2M/tVuP+9wF8Bu8NTLDKz1YOVJdOSpcBNN3Wtc87lsmSB5HrgCiACnJewbdDEVpLygTuAs4BGYIWkZfHT0UuqA24GTjOzXZJiycf3A1eZ2VuSpgKrJC03s+Zwe9aHH8en2p01Ds4a8w6tzTuor69nwYIFFBYWsq29k3sTUtf+69E1XDR5PGX5w5P7wznnsm3AQGJmf5T030Cjmd02hHOfAmw0s00Aku4Hzgfi85p8AbjDzHaFn7kt/PlmXDm2SNoGVAHN5ID4aeRn5DVxSvu77G4XR59yJud++nRe3bOfO9/awrJtzXSZceaEcXyhpoq/HF/uzVfOuUNOKpM2ngsMJZBUAw1x7xuBjyXsczSApBcImr9uMbMn4neQdApQBLwdt/o2Sf9CkEf+JjNrJ4Gk64DrAKZNmzaE4g8slmr3+PwtnFi4mQ+7y3mucyYFm+GBVW+ycs9+yvPzWFQ9gWuqq5gxxpuvnHOHrlSG/z4p6SLgIRssC1Zf/f3pnXh8AVAHfBKoAf4g6bhYE5akKcDPgavNLJYv/mbgA4LgsgT4KnDrAR9ktiTcTn19/cGUe1Cbw1S773WPJ6p81tTMoqu2HEryKevs4tt11cOautY553JZKoHky0AZEJXUSm+GxHGDHNcIxD84UQNs6Wefl8ysE3hH0gaCwLJC0jjgMeBrZvZS7AAz2xoutku6B/hKCt9hWOVLRM1oqp3Ih0fPgnyRt6ONwvXNvPDlM4Y9da1zzuWyVCZtHHguj+RWAHWSZgCbgUuByxP2eQS4DLhX0kSCpq5NkoqAh4GfmdnS+AMkTTGzrQo6Gy4AXh9i+YYsGt6YaV8X+ZtbyH+/hbyWLgAPIs65w86gT74pcKWkr4fva8N+i6TMrAu4AVgOvAH82szWSbpVUiyXyXKgSdJ64BmC0VhNwCXAJ4BFklaHr7nhMfdJWgusBSYC3z6obzwMqiPBw4X5O9spfGN3TxCJrXfOucOJBuv2kPRjoBs4w8yOkTQeeNLMTk56YA6pr6+3lStXDtv54kdtxZQW5vOdC+cMW/pd55zLNkmrzKx+sP1S6SP5mJmdKOlVgPB5j8N6EqhYsIg9RzI1UsriBbM9iDjnDkupBJLO8OFCg55p5LuTH3Lou2BetQeOJOIf2PRAeyCvn+S8fpLLtfpJJZD8kKDje5Kk24CLga9ltFRuVEts+tvc3MrND60F8IsBXj+D8fpJLhfrJ5VRW/dJWgXMJxj6e4GZvZHxkrlRwbqNzo4one3Bq6sjyj2PbuCI/UaR5ZEfe5yoA5Y+uIFjOvzZmqW/2cD0/RA8gxvy+unh9ZNcfP1EMd4s6qa1M8r3lm/IWiAZsLNdUgnBfFtHEYyQuisciTXqDHdn+2hkZkS7uoMLflu0z8W/s61vIEhc13nAuq5wfTdd7dHBP9w5lxGtMn5U0QYEf+W/c/unh/X8w9HZ/lOgE/gDcA5wDPCl4Sne6JfJNsruaHfvRfwgXl2DbLfu1B/wLyjMo6A4n8KEV+nYwgPWFRTnU9TzvoDFj6xla0s7nTK66J3OYPK4Eu6/7uPDUkej2aVLXuKDPW0HrPf6CXj9JDdQ/UzN4uMHyQLJsWY2B0DSXcDLI1Ok3NfTRtkRpRDYtbOV7yxdS2dTG6dPn9D3L/m2hAt6f+sSgkC0K/WxDHl5orDkwAt+WUVRv4GgMO6CP9C2guJ88vKG/mDl55kdtuH2fo/SwnyuP3c2kSPGDPm8h4rrz53d7/Bxr5+A109yA9XP4gWzs1amZIGkM7ZgZl0+a22v2KSNp7YXcHpbYc/6bQ+8x0O81/9BIrhQF4UX7PDiX1JWwNjxxb0X8nB9QZ/94i76Rfl9Akd+Qe5lU/Th0cl5/STn9ZNcLtZPsj6SKNASewuUEuQJSXWurZwx3H0kM256DAOmduVR3ZVHp4wOQSfG3dd+jMKSuEAQBoOCwjyfQt45N6qk3UdiZj48YgBTI6Vsbm5lS0E3Wwp6m2+qI6XUHluZxZI559zIy712kVFg8YLZlBb2jbPZbqN0zrlsSeWBRJcgF9sonXMuWzyQDJFPkeKccwFv2nLOOZcWDyTOOefS4oHEOedcWjyQOOecS0tGA4mkhZI2SNoo6aYB9rlE0npJ6yT9Im791ZLeCl9Xx60/SdLa8Jw/lD/l55xzWZWxUVthMqw7gLOARmCFpGVmtj5unzrgZuC0MPPipHB9JfANoJ5gzr9V4bG7gB8D1wEvAf8FLAQez9T3cM45l1wm70hOATaa2SYz6wDuB85P2OcLwB1hgMDMtoXrFwBPmdnOcNtTwEJJU4BxZvaiBXO7/Ay4IIPfwTnn3CAyGUiqgYa4943hunhHA0dLekHSS5IWDnJsdbic7JwASLpO0kpJK7dv357G13DOOZdMJgNJf30XiTNEFgB1wCeBy4A7JUWSHJvKOYOVZkvMrN7M6quqqlIutHPOuYOTyUDSCNTGva8BtvSzz6Nm1mlm7wAbCALLQMc2hsvJzumcc24EZTKQrADqJM2QVARcCixL2OcR4FMAkiYSNHVtApYDZ0saL2k8cDaw3My2AnslfTwcrXUV8GgGv4NzzrlBZGzUVpgM6waCoJAP3G1m6yTdCqw0s2X0Boz1QBRYbGZNAJK+RRCMAG41s53h8t8C9xLkR3kcH7HlnHNZNWBiq0PJcCe2coPLZE5759zISDuxlXND1ZPTPswpvbm5lZsfWgvgwcS5Q5BPkeKGXSynfbzWzij/+sSfs1Qi51wm+R2JS1tLexdrN+9mdUMzaxqa2dzc2u9+W3a3ce6//4FZVeUcVVXOrEnlzKoq58gJYygp9MzOzo1WHkjcQYl2G29+uLcnaKxuaObND/fSHXa1TascQ2lh/gF3JABlRflUlhWz8t1dPLq6d9R2nqC2cgyzqsqZVVUW/AyDTGVZ0Uh9NefcEHkgcQMyMz7Y08bq94OA8WpDM69v3s3+jiBIVJQWMrc2wtkfncy82ggn1EaoLCs6oI8Egpz2t312Tk8fyf6OLjZtb+Ht7ft4O/Zz2z7+uHEHHV3dPceNH1PIUWFQCQJMEGhqxo8hP8/n63QuF/ioLddjb1snaxt3s7qxuSd4bNvbDkBRfh7HTB3HvNoIc8OgMX3CGAaafHmoo7ai3caW5lY2hoElFmQ2bd/Hjn0dPfsV5ecxY2JZT2CJvWZWlVFW7H8fOTccUh215YHkMNUV7WZD2ES1+v1m1jQ289a2fcT+OcyYWBYEjJoK5k4bzzFTxlJckN1+jF0tHWzasY+3t8XuZIJA815TS0/TGsDUipKeprH4prJJY4sHDHzOuQP58F/Xw8zY3Nzap19j7ebdtHUGTUiVZUWcUFPBp+dMZe60IHhExuRe38T4siJOKqvkpCMr+6xv74ryftP+3maybfvYuH0fS1c20NLR27xWXlyQ0AdTFnb2l1FU4AMYnRsqDySHoN2tYRNVw67gjqNhNzv2hU1UBXkcN3Ucl59yJCfUVjCvdjy1laWj+i/14oJ86o4YS90RY/usNzM+3NPee/cSNpW9uKmJh17d3LNffp44snIMM+P6YGIjyyrGFI7013Fu1PFAMsp1Rrv589a9YdAIgsfb21t6ts+qKuMTR08M+zbGM3vy2MPmr29JTK4oYXJFCacdNbHPtn3tXbwT9r9s3LavJ9g8/+Z2OqK9nf0Ty4uCABNrJpsUBJjqSCl53tnvHOCBZFQxMxp2tsZ1hu9i3ZY9tIejnCaWFzG3NsJn51VzQm2E42siVJT6X9T9KS8uYE5NBXNqKvqs74p207irNe4uJgg2j7++leb9nT37FRfkhQGmb1PZzInllBb5MzHu8OKd7Tls9/7OnqCxpjHo32hqCUYulRTmMae6ghNqIsydFoykqo6M7iaqXLezpaP3DmZbb2d/w679xP83qo6U9umDiQ1fnlhe1PP78bnIkvP6SW6k6sdHbcUZDYGkvSvKG1v39nSGr25o5p0dQROVBHWTynuCxgk1EWZPHkth/uHRRJXr2jqjvNvUkjCaLLibiX+WZlxJAbMmlVOYl8cr7++iK26oWXFBHjeeUcenPjIpG18hpzzz52388Om3eu60wesnXn/1U1qYz3cunDPswcQDSZxcCyRmxntN+3sCxuqGZtZv2dPTNj9pbDFza8M7jZoIc2oqGFviTVSjTXe3sXVPW9zdSxBc/vROU5/hys4Nh+pIKS/cdMawntOH/+aQnS0dfe401jQ297S3jynKZ051BX9z2vSe4DF5XIk3UR0C8vJEdaSU6kgpnzi6N93zjJseG/CY/3/lSSNRtJx2/X+uGnCb18/A9bNlgDnuRoIHkiEaqI2yrTPK+q17ep4MX9PYzHtN+4FgTqmjjxjLwo9O7nk6vG5SOQXeRHVYmRop7Xdiy+pIKQuPm5yFEuWWaq+fpAaqn6mR0iyUJuCBZAj6y7fxj0vX8H+f3MAHe9rojAbtFlMqSphbG+GyU6YxtzbCnOoKn77DsXjB7H7nIlu8YHYWS5U7vH6Sy8X6yehVTdJC4AcEqXbvNLPbE7YvAr4HxJ4O+5GZ3SnpU8D343b9CHCpmT0i6V7gr4Dd4bZFZrY6c9/iQP3l24h2Gx/ubefav5wZNFHVRjhiXMlIFsuNErEOUR+V1D+vn+RysX4y1tkuKR94EzgLaCTIv36Zma2P22cRUG9mNyQ5TyWwEagxs/1hIPmtmT2QalmGu7N9xk2P0V+tCXjn9k8P2+c451w2pdrZnsnG+VOAjWa2ycw6gPuB84dwnouBx81s/7CWLg0DtUVms43SOeeyJZOBpBpoiHvfGK5LdJGk1yQ9IKm2n+2XAr9MWHdbeMz3JRX39+GSrpO0UtLK7du3D+kLDGTxgtmUJmT0y3YbpXPOZUsmA0l/41cTW4R+A0w3s+OB3wE/7XMCaQowB1get/pmgj6Tk4FK4Kv9fbiZLTGzejOrr6qq6m+XIbtgXjXfuXBO8CQ5wSiKTDwM5Jxzo0EmO9sbgfg7jBpgS/wOZtYU9/YnwHcTznEJ8LCZdcYdszVcbJd0D/CVYSvxQbhgXrUHDuecI7N3JCuAOkkzJBURNFEti98hvOOI+QzwRsI5LiOhWSt2jIIn9i4AXh/mcjvnnDsIGbsjMbMuSTcQNEvlA3eb2TpJtwIrzWwZcKOkzwBdwE5gUex4SdMJ7mieSzj1fZKqCJrOVgPXZ+o7OOecG5zPteWcc65fuTD81znn3GHAA4lzzrm0eCBxzjmXFg8kzjnn0uKBxDnnXFo8kDjnnEuLBxLnnHNp8UDinHMuLR5InHPOpcUDiXPOubR4IHHOOZcWDyTOOefS4oHEOedcWjyQOOecS4sHEuecc2nxQOKccy4th0ViK0nbgfcydPqJwI4MnftQ4PWTnNdPcl4/yWW6fo40s6rBdjosAkkmSVqZSgaxw5XXT3JeP8l5/SSXK/XjTVvOOefS4oHEOedcWjyQpG9JtguQ47x+kvP6Sc7rJ7mcqB/vI3HOOZcWvyNxzjmXFg8kzjnn0uKBZBhI+l+S1knqlpT1oXi5QtJCSRskbZR0U7bLk0sk3S1pm6TXs12WXCSpVtIzkt4I/299MdtlyiWSSiS9LGlNWD/fzGZ5PJAMj9eBC4Hns12QXCEpH7gDOAc4FrhM0rHZLVVOuRdYmO1C5LAu4B/N7Bjg48Df+b+fPtqBM8zsBGAusFDSx7NVGA8kw8DM3jCzDdkuR445BdhoZpvMrAO4Hzg/y2XKGWb2PLAz2+XIVWa21cxeCZf3Am8A1dktVe6wwL7wbWH4ytrIKQ8kLlOqgYa49434hcANgaTpwDzgT9ktSW6RlC9pNbANeMrMslY/Bdn64NFG0u+Ayf1s+mcze3SkyzMKqJ91PtbcHRRJ5cCDwJfMbE+2y5NLzCwKzJUUAR6WdJyZZaXPzQNJiszszGyXYZRpBGrj3tcAW7JUFjcKSSokCCL3mdlD2S5PrjKzZknPEvS5ZSWQeNOWy5QVQJ2kGZKKgEuBZVkukxslJAm4C3jDzP4t2+XJNZKqwjsRJJUCZwJ/zlZ5PJAMA0mfldQInAo8Jml5tsuUbWbWBdwALCfoKP21ma3Lbqlyh6RfAi8CsyU1Svrf2S5TjjkN+DxwhqTV4euvs12oHDIFeEbSawR/tD1lZr/NVmF8ihTnnHNp8TsS55xzafFA4pxzLi0eSJxzzqXFA4lzzrm0eCBxzjmXFg8kLmsk7Rt8r4M633SfTbeXpH/KwmfeK+nikf5cl10eSJwbIklpzwwRzpKcKQcdSDJcHneI8kDicoqkIyX9XtJr4c9p4fpZkl6StELSrUnuZvIl/STM0fCkpNLw2FfiPqNO0qpw+V1J3w1zO7ws6ahwfZWkB8PPWyHptHD9LZKWSHoS+JmkRZIelfREmHvlG3Gf84ikVWFZrotbvy/8Dn8CTpX0L+FnvB6eW+F+z0r6vqTnw7wcJ0t6SNJbkr4dd74rw7KvlvQf4WR+twOl4br7Btqvv/LEnfcYSS/HvZ8ePgDHQGVO+F2+K2liuFwfTuOBpDIF+VhWSHpVks8KPdqZmb/8lZUXsK+fdb8Brg6XrwEeCZd/C1wWLl8/wLHTCfJYzA3f/xq4Mlx+Jm79/wH+Plx+l2DiTYCrgN+Gy78ATg+XpxFM1QFwC7AKKA3fLwK2AhOAUoK5jurDbZXhz9j6CeF7Ay6JK3dl3PLPgfPC5WeB74bLXySYq2wKUEwwl9kE4JiwzgrD/f4fcFVi/Q6yX5/yJNTpamBmuPxV4GuDlPle4OK4up0YLtcDz8bVf+z3EgHeBMqy/e/RX0N/+R2JyzWnElzEIbhAnR63fmm4/IvEg+K8Y2arw+VVBMEF4E7gb8K/wj+XcI5fxv2M/UV+JvCjcJruZcA4SWPDbcvMrDXu+KfMrClc91BcmW+UtAZ4iWACy7pwfZRgMsKYT0n6k6S1wBnAR+O2xeYnWwussyBPRzuwKTznfOAkYEVY1vnAzH7qJdl+ieWJ92vgknD5c8CvUijzYM4GbgrL8SxQQhCs3Sjls/+6XHewc/i0xy1HCe4GILhQfgN4GlhlZk0DfEZsOQ84NSFgELbgtAxSRpP0SYJgdKqZ7Q+bdUrC7W0WTAGOpBKCu4N6M2uQdEvcfvHfpzvhu3UT/P8V8FMzu5nkku3XU55+/ApYKukhgnxKb6VQ5pguepvP47cLuMg8Gdwhw+9IXK75b4KZggGuAP4YLr8EXBQuX5p40GDMrI1gAskfA/ckbP5c3M8Xw+UnCSadBEDS3CSnP0tSpYJZWC8AXgAqgF1hEPkIQbrY/sQusDsU5N442BFPvwculjQpLGelpCPDbZ0KpmIfbL8BmdnbBAH56/TejaRa5ncJ7oKg93cHwe/h7+P6guYNVg6X2zyQuGwao2Dm29jry8CNBE1QrxHM/vrFcN8vAV8OO3+nALuH8Hn3Edw9PJmwvjjsaP4i8A/huhuBegWd/usJ+mUG8keCZrjVwINmthJ4AigIv8e3CALhAcysGfgJQdPVIwQzuabMzNYDXwOeDD/rKYL6AVgCvCbpvkH2G8yvgCsJmrkOpszfBH4g6Q8EwSjmWwSpYV9TMFz7WymWw+Uon/3XjQqSxgCtZmaSLiXoeD+o0T6SvgJUmNnX49a9S9BEs2OI5VoUHn/DYPs6d6jyPhI3WpxE0PktoJlgRFfKJD0MzCLoGHbODSO/I3HOOZcW7yNxzjmXFg8kzjnn0uKBxDnnXFo8kDjnnEuLBxLnnHNp+R8CYfs5V96F4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24c98ef14a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_cv(clf, params_grid, param = 'C'):\n",
    "    params = [x for x in params_grid[param]]\n",
    "  \n",
    "    keys = list(clf.cv_results_.keys())              \n",
    "    grid = np.array([clf.cv_results_[key] for key in keys[6:16]])\n",
    "    means = np.mean(grid, axis = 0)\n",
    "    stds = np.std(grid, axis = 0)\n",
    "    print('Performance metrics by parameter')\n",
    "    print('Parameter   Mean perforance   STD performance')\n",
    "    for x,y,z in zip(params, means, stds):\n",
    "        print('%8.2f      %6.5f              %6.5f' % (x,y,z))\n",
    "    \n",
    "    params = [math.log10(x) for x in params]\n",
    "    \n",
    "    plt.scatter(params * grid.shape[0], grid.flatten())\n",
    "    p = plt.scatter(params, means, color = 'red', marker = '+', s = 300)\n",
    "    plt.plot(params, np.transpose(grid))\n",
    "    plt.title('Performance metric vs. log parameter value\\n from cross validation')\n",
    "    plt.xlabel('Log hyperparameter value')\n",
    "    plt.ylabel('Performance metric')\n",
    "    \n",
    "plot_cv(clf, param_grid)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of points to notice here:\n",
    "1. The mean AUC for each value of the hyperparameter are all within 1 standard deviation of each other. This result indicates that model performance is not sensitive to the choice of hyperparamter. \n",
    "2. Graphically you can see that there is a noticeable variation in the AUC from metric to metric, regardless of hyperparameter. Keep in mind that **this variation is simply a result of random sampling of the data!**\n",
    "\n",
    "Finally, it is time to try execute the outer loop of the nested cross validation to evaluate the performance of the 'best' model selected by the inner loop. In this case, 'best' is quite approximate, since as already noted, the differences in performance between the models is not significant. \n",
    "\n",
    "The code in the cell below executes the outer loop of the nested cross validation using the `cross_val_scores` function from the Scikit Learn `model_selection` package. The folds are determined by the `outside` k-fold object. The mean and standard deviation of the AUC is printed along with the value estimated for each fold. Execute this code and examine the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean performance metric = 0.667\n",
      "SDT of the metric       = 0.050\n",
      "Outcomes by cv fold\n",
      "fold 1   0.745\n",
      "fold 2   0.701\n",
      "fold 3   0.661\n",
      "fold 4   0.687\n",
      "fold 5   0.712\n",
      "fold 6   0.657\n",
      "fold 7   0.563\n",
      "fold 8   0.695\n",
      "fold 9   0.627\n",
      "fold 10   0.625\n"
     ]
    }
   ],
   "source": [
    "nr.seed(498)\n",
    "cv_estimate = ms.cross_val_score(clf, Features, Labels, \n",
    "                                 cv = outside) # Use the outside folds\n",
    "print('Mean performance metric = %4.3f' % np.mean(cv_estimate))\n",
    "\n",
    "print('SDT of the metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by cv fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('fold ' + str(i+1) + '   %4.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, there is considerable variation in AUC across the folds. The mean AUC is a bit lower than estimated for the inner loop of the nested cross validation and the baseline model. However, all of these values are within 1 standard deviation of each other, and thus these differences cannot be considered significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab you have performed by simple cross validation and nested cross validation. Key points and observations are:\n",
    "1. Model selection should be done using a resampling proceedure such as nested cross validation. The nested sampling structure is required to prevent bias in model selection wherein the model selected learns the best hyperparameters for the samples used, rather than a model that generalizes well. \n",
    "2. There is significant variation in model performance from fold to fold in cross validation. This variation arrises from the sampling of the data alone and is not a property of any particular mdoel.\n",
    "3. Given the expected sampling variation in cross validation, there is generally considerable uncertainty as to which model is best when performing model selection.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
